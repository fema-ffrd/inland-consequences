{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Consequences Solution \u00b6 Consequence modeling is essential for actuarial assessments, scenario evaluations, and Benefit-Cost Analyses (BCAs) . Accurate Annualized Average Loss (AAL) data supports setting insurance premiums, managing financial risks, planning for emergencies, and justifying investments in flood mitigation. FEMA requires rapid and reliable AAL estimates to improve flood damage assessments. The Consequences Solution is designed to deliver a flexible and transparent framework that meets FEMA\u2019s needs by leveraging established methodologies to produce trusted AAL data for both coastal and inland areas. Inland and Coastal Framework This solution introduces a unified inland and coastal modeling framework that applies best practices and lessons learned from existing hazard and loss modeling tools. By aligning inland and coastal approaches within a single architecture, the framework enables loss calculations for both flood types using a common solution. The framework is intentionally designed to be modular, allowing individual components to be updated, extended, or replaced over time as methodologies evolve or new data sources and capabilities are introduced. Integration with Coastal FFRD Methodology The Consequences Solution migrates the Coastal Future of Flood Risk Data (FFRD) Average Annualized Loss Calculation Tool from R to Python , integrating its core methodology into a modular, scalable architecture.This migration facilitates continued development and performance enhancements while ensuring methodological consistency with ongoing FEMA projects. Phased Approach to Inland Consequence The Inland Consequences Solution enables inland flood loss modeling using depth-based hazard inputs, supporting both single-event loss calculations and multi\u2013return-period average annualized loss (AAL) analyses. In the context of Future Flood Risk Data (FFRD), the current phase of development focuses on calculating AAL from post-processed annual exceedance probability (AEP) depth rasters and their associated velocity, duration, and uncertainty layers. A planned future enhancement is to leverage the full FFRD event catalog to support event-based loss calculations and a more comprehensive treatment of uncertainty. Key Benefits Consistency \u2013 Unified inland and coastal methodologies ensure compatibility across FEMA risk products. Transparency \u2013 Open, modular framework simplifies review and reproducibility. Extensibility \u2013 Supports future enhancements, such as new hazard inputs or improved structure inventories. Efficiency \u2013 Modernized Python implementation reduces manual processing time and enables integration with cloud-based workflows.","title":"Consequences Solution"},{"location":"#consequences-solution","text":"Consequence modeling is essential for actuarial assessments, scenario evaluations, and Benefit-Cost Analyses (BCAs) . Accurate Annualized Average Loss (AAL) data supports setting insurance premiums, managing financial risks, planning for emergencies, and justifying investments in flood mitigation. FEMA requires rapid and reliable AAL estimates to improve flood damage assessments. The Consequences Solution is designed to deliver a flexible and transparent framework that meets FEMA\u2019s needs by leveraging established methodologies to produce trusted AAL data for both coastal and inland areas. Inland and Coastal Framework This solution introduces a unified inland and coastal modeling framework that applies best practices and lessons learned from existing hazard and loss modeling tools. By aligning inland and coastal approaches within a single architecture, the framework enables loss calculations for both flood types using a common solution. The framework is intentionally designed to be modular, allowing individual components to be updated, extended, or replaced over time as methodologies evolve or new data sources and capabilities are introduced. Integration with Coastal FFRD Methodology The Consequences Solution migrates the Coastal Future of Flood Risk Data (FFRD) Average Annualized Loss Calculation Tool from R to Python , integrating its core methodology into a modular, scalable architecture.This migration facilitates continued development and performance enhancements while ensuring methodological consistency with ongoing FEMA projects. Phased Approach to Inland Consequence The Inland Consequences Solution enables inland flood loss modeling using depth-based hazard inputs, supporting both single-event loss calculations and multi\u2013return-period average annualized loss (AAL) analyses. In the context of Future Flood Risk Data (FFRD), the current phase of development focuses on calculating AAL from post-processed annual exceedance probability (AEP) depth rasters and their associated velocity, duration, and uncertainty layers. A planned future enhancement is to leverage the full FFRD event catalog to support event-based loss calculations and a more comprehensive treatment of uncertainty. Key Benefits Consistency \u2013 Unified inland and coastal methodologies ensure compatibility across FEMA risk products. Transparency \u2013 Open, modular framework simplifies review and reproducibility. Extensibility \u2013 Supports future enhancements, such as new hazard inputs or improved structure inventories. Efficiency \u2013 Modernized Python implementation reduces manual processing time and enables integration with cloud-based workflows.","title":"Consequences Solution"},{"location":"AAL_tech_implementation/","text":"Average Annualized Loss (AAL) Technical Implementation \u00b6 The inland consequence methodology computes Average Annualized Loss (AAL) using a numerical integration approach consistent with the method implemented in FEMA\u2019s Hazus Program. The recommended implementation leverages the AAL calculation code developed for SPHERE , which is directly adapted from the Hazus Riemann sum formulation. This approach does not require a fixed set or number of return periods; instead, it operates on all available modeled frequencies and loss estimates provided by the user. AAL Calculation Method \u00b6 The AAL is calculated using a discrete Riemann sum that integrates the loss\u2013exceedance relationship across all provided return periods. The function below shows the reference implementation adapted from the Hazus Technical Manual. It expects: Inputs: in_rpnames : a sorted (ascending) list of return periods in_losses : a list of loss values corresponding to each return period The function returns a single numeric AAL value. #Formula adapted from Hazus Technical Manual # IN: # in_rpnames = SORTED (ascending) list of return periods that pair sequentially with in_losses # in_losses = list of losses that pair sequentially with in_rpnames # OUT: # numeric value representing adjusted loss def calc_aal(in_rpnames, in_losses): SumAnnLoss = 0 for i in range(len(in_losses)): if i == (len(in_losses) - 1): SumAnnLoss += (1 / in_rpnames[i]) * (in_losses[i]) else: SumAnnLoss += ((1 / in_rpnames[i]) - (1 / in_rpnames[i + 1])) * (((in_losses[i]) + (in_losses[i + 1])) / 2) return SumAnnLoss This formulation treats each return-period pair as a point on the loss-exceedance curve and computes the integrated area beneath the curve. Truncation Option \u00b6 The methodology supports two AAL calculation modes: non-truncated (default) and truncated. Non-Truncated AAL (Default, 0) \u00b6 Includes all provided return periods, even those with $0 loss. When the lowest-frequency return period has $0 loss, the $0 value is averaged with the next nonzero period. Example: 50-year loss = $0 100-year loss = $1,200 Average used in integration = (0 + 1,200) / 2 = $600 This follows the Hazus approach and provides a more conservative AAL estimate. Truncated AAL (1) \u00b6 Excludes the $0-loss return period from the summation. This approach aligns with the GoConsequences implementation. Generally produces lower AAL values, particularly when few frequencies are supplied. Users should select the truncation setting based on analysis goals, regulatory requirements, or consistency with other modeling frameworks. Minimum Return Period Requirements \u00b6 To ensure stable and interpretable AAL results, the tool should require at least three return periods. While the Riemann sum method can operate with fewer, accuracy improves substantially as more frequencies are included, particularly higher-frequency (smaller return period) events. Loss estimates become more reliable with a greater number of return periods; therefore, for best results, users should provide as many frequencies as possible across the full range of the hazard. Future enhancements may include tooltip guidance on selecting appropriate return periods and automated detection of return periods from file names. However, the current implementation requires users to enter all return period values explicitly.","title":"Average Annualized Loss (AAL) Technical Implementation"},{"location":"AAL_tech_implementation/#average-annualized-loss-aal-technical-implementation","text":"The inland consequence methodology computes Average Annualized Loss (AAL) using a numerical integration approach consistent with the method implemented in FEMA\u2019s Hazus Program. The recommended implementation leverages the AAL calculation code developed for SPHERE , which is directly adapted from the Hazus Riemann sum formulation. This approach does not require a fixed set or number of return periods; instead, it operates on all available modeled frequencies and loss estimates provided by the user.","title":"Average Annualized Loss (AAL) Technical Implementation"},{"location":"AAL_tech_implementation/#aal-calculation-method","text":"The AAL is calculated using a discrete Riemann sum that integrates the loss\u2013exceedance relationship across all provided return periods. The function below shows the reference implementation adapted from the Hazus Technical Manual. It expects: Inputs: in_rpnames : a sorted (ascending) list of return periods in_losses : a list of loss values corresponding to each return period The function returns a single numeric AAL value. #Formula adapted from Hazus Technical Manual # IN: # in_rpnames = SORTED (ascending) list of return periods that pair sequentially with in_losses # in_losses = list of losses that pair sequentially with in_rpnames # OUT: # numeric value representing adjusted loss def calc_aal(in_rpnames, in_losses): SumAnnLoss = 0 for i in range(len(in_losses)): if i == (len(in_losses) - 1): SumAnnLoss += (1 / in_rpnames[i]) * (in_losses[i]) else: SumAnnLoss += ((1 / in_rpnames[i]) - (1 / in_rpnames[i + 1])) * (((in_losses[i]) + (in_losses[i + 1])) / 2) return SumAnnLoss This formulation treats each return-period pair as a point on the loss-exceedance curve and computes the integrated area beneath the curve.","title":"AAL Calculation Method"},{"location":"AAL_tech_implementation/#truncation-option","text":"The methodology supports two AAL calculation modes: non-truncated (default) and truncated.","title":"Truncation Option"},{"location":"AAL_tech_implementation/#non-truncated-aal-default-0","text":"Includes all provided return periods, even those with $0 loss. When the lowest-frequency return period has $0 loss, the $0 value is averaged with the next nonzero period. Example: 50-year loss = $0 100-year loss = $1,200 Average used in integration = (0 + 1,200) / 2 = $600 This follows the Hazus approach and provides a more conservative AAL estimate.","title":"Non-Truncated AAL (Default, 0)"},{"location":"AAL_tech_implementation/#truncated-aal-1","text":"Excludes the $0-loss return period from the summation. This approach aligns with the GoConsequences implementation. Generally produces lower AAL values, particularly when few frequencies are supplied. Users should select the truncation setting based on analysis goals, regulatory requirements, or consistency with other modeling frameworks.","title":"Truncated AAL (1)"},{"location":"AAL_tech_implementation/#minimum-return-period-requirements","text":"To ensure stable and interpretable AAL results, the tool should require at least three return periods. While the Riemann sum method can operate with fewer, accuracy improves substantially as more frequencies are included, particularly higher-frequency (smaller return period) events. Loss estimates become more reliable with a greater number of return periods; therefore, for best results, users should provide as many frequencies as possible across the full range of the hazard. Future enhancements may include tooltip guidance on selecting appropriate return periods and automated detection of return periods from file names. However, the current implementation requires users to enter all return period values explicitly.","title":"Minimum Return Period Requirements"},{"location":"building_inventories/","text":"Building Inventories Technical Implementation \u00b6 The Consequence Modeling Solution is designed to natively ingest the National Structures Inventory (NSI) and the Milliman Market Basket datasets out of the box, while also providing a pathway for users to integrate their own custom inventory data . Table 1 identifies the supported data sources, versions, expected input formats, and applicable consequence-modeling pathways. Table 1. Supported Inventory Data Sources Data Source Version Input File Type Consequence Modeling NSI 2022 Public Version GeoPackage Inland, Coastal NSI 2022 FEMA-Enhanced Version File Geodatabase Inland only Milliman Market Baskets 2021 Uniform, Uncorrelated Comma-Separated Values (CSV) Inland, Coastal User-defined Inventories User-defined User-defined Inland, Coastal For additional details on inventory requirements and methodology, refer to the Inventory Methodology Documentation . Inventory Ingestion and Processing Approach \u00b6 Regardless of which inventory type is provided, several required fields must be present to support loss calculations. However, the Consequence Solution is designed to minimize the amount of data preprocessing required from the user by implementing the following strategies: Auto-detection of required fields based on common naming conventions Auto-population of missing fields using documented default values User-provided overrides for NSI and Milliman field names Comprehensive documentation for each inventory source, including requirements for user-defined datasets Schema validation to ensure completeness and correctness prior to modeling Base Buildings Class \u00b6 The Base Buildings Class provides standardized field mapping for building inventories. It defines target fields that all consequence analysis operations use, but does not validate or impute missing fields . The base class simply maps source field names (via auto-detection or explicit overrides) to standardized target field names. Subclasses extend the base class with schema validation and field imputation: NsiBuildings : Validates NSI required fields and imputes optional fields using NSI-specific defaults MillimanBuildings : Validates Milliman required fields and imputes optional fields (including creating fields not present in source data like occupancy_type and area ) User-defined : Can use base Buildings class directly (requires all fields present) or create a custom subclass with validation/imputation The Buildings class provides flexible field mapping through: Automatic field detection using case-insensitive matching against common aliases Explicit field overrides for non-standard field names Property-based access to all target fields regardless of source naming Base Buildings Schema \u00b6 The following schema defines all target fields used by the Consequence Modeling Solution. Table 1 provides a summary of the target fields, their data types, and usage context. Table 1. Base Buildings Target Fields Target Field Data Type Description Used In Common Aliases id String Unique identifier for the building Inland, Coastal id, building_id, bldg_id, fd_id occupancy_type String HAZUS occupancy classification (e.g., RES1, COM1, IND2) Inland, Coastal occupancy_type, occtype, occupancy, occ_type, building_type first_floor_height Numeric First floor height above ground elevation (feet) Inland, Coastal first_floor_height, found_ht, first_floor_ht, ffh, floor_height foundation_type String Foundation type code (BASE, PILE, SHAL, SLAB) Inland, Coastal foundation_type, fndtype, found_type, fnd_type number_stories Numeric Number of stories (floors) in the building Inland, Coastal number_stories, num_story, numstories, stories, num_floors area Numeric Building floor area (square feet) Inland, Coastal area, sqft, building_area, floor_area building_cost Numeric Building structural replacement cost (USD) Inland, Coastal buildingcostusd, building_cost, val_struct, cost, building_value content_cost Numeric Contents replacement cost (USD) Inland, Coastal contentcostusd, content_cost, val_cont, contents_cost inventory_cost Numeric Business inventory replacement cost (USD) Inland, Coastal inventorycostusd, inventory_cost, val_inv, inv_cost general_building_type String Construction material code (W, M, C, S, MH) Inland general_building_type, bldgtype, generalbuildingtype eq_building_type String Earthquake-specific building type classification Earthquake eqbldgtypeid, eq_building_type, earthquake_building_type eq_design_level String Earthquake design level classification Earthquake eqdesignlevelid, eq_design_level, design_level Base Buildings Data Schema: \u00b6 { \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"$id\": \"https://example.com/schemas/buildings_schema.json\", \"title\": \"Base Buildings Schema\", \"version\": \"0.1.0\", \"description\": \"Base schema defining standardized target fields for building inventories. The base Buildings class performs field mapping only. Specific implementations (NsiBuildings, MillimanBuildings) extend the base class with schema validation and field imputation. The 'required' attribute indicates whether a field must be present for consequence analysis, not whether the base class validates it.\", \"target fields\": { \"id\": { \"type\": \"string\", \"description\": \"Unique identifier for the building\", \"required\": true, \"nullable\": false, \"used_in\": [\"inland\", \"coastal\"], \"aliases\": [\"id\", \"building_id\", \"bldg_id\", \"fd_id\"] }, \"occupancy_type\": { \"type\": \"string\", \"description\": \"Occupancy type code following HAZUS classification (e.g., RES1, COM1, IND2)\", \"required\": true, \"nullable\": false, \"used_in\": [\"inland\", \"coastal\"], \"aliases\": [\"occupancy_type\", \"occtype\", \"occupancy\", \"occ_type\", \"building_type\"] }, \"first_floor_height\": { \"type\": \"number\", \"description\": \"First floor height above ground elevation (feet)\", \"required\": true, \"nullable\": false, \"used_in\": [\"inland\", \"coastal\"], \"aliases\": [\"first_floor_height\", \"found_ht\", \"first_floor_ht\", \"ffh\", \"floor_height\"] }, \"foundation_type\": { \"type\": \"string\", \"description\": \"Foundation type code for inland flood modeling (I=Pile, P=Pier, W=Solid Wall, B=Basement, C=Crawl, F=Fill, S=Slab)\", \"required\": true, \"nullable\": false, \"used_in\": [\"inland\", \"coastal\"], \"enum\": [\"I\", \"P\", \"W\", \"B\", \"C\", \"F\", \"S\"], \"aliases\": [\"foundation_type\", \"fndtype\", \"found_type\", \"fnd_type\"] }, \"number_stories\": { \"type\": \"number\", \"description\": \"Number of stories (floors) in the building\", \"required\": true, \"nullable\": false, \"used_in\": [\"inland\", \"coastal\"], \"aliases\": [\"number_stories\", \"num_story\", \"numstories\", \"stories\", \"num_floors\", \"floors\"] }, \"area\": { \"type\": \"number\", \"description\": \"Building floor area in square feet\", \"required\": true, \"nullable\": false, \"used_in\": [\"inland\", \"coastal\"], \"aliases\": [\"area\", \"sqft\", \"building_area\", \"floor_area\"] }, \"building_cost\": { \"type\": \"number\", \"description\": \"Building structural replacement cost in US dollars\", \"required\": true, \"nullable\": false, \"used_in\": [\"inland\", \"coastal\"], \"aliases\": [\"buildingcostusd\", \"building_cost\", \"val_struct\", \"cost\", \"replacement_cost\", \"building_value\"] }, \"content_cost\": { \"type\": \"number\", \"description\": \"Contents replacement cost in US dollars\", \"required\": true, \"nullable\": false, \"used_in\": [\"inland\", \"coastal\"], \"aliases\": [\"contentcostusd\", \"content_cost\", \"val_cont\", \"contents_cost\"] }, \"inventory_cost\": { \"type\": \"number\", \"description\": \"Business inventory replacement cost in US dollars\", \"required\": true, \"nullable\": false, \"used_in\": [\"inland\", \"coastal\"], \"aliases\": [\"inventorycostusd\", \"inventory_cost\", \"val_inv\", \"inv_cost\"] }, \"general_building_type\": { \"type\": \"string\", \"description\": \"General construction type code (W=Wood, M=Masonry, C=Concrete, S=Steel, MH=Manufactured Housing)\", \"required\": true, \"nullable\": false, \"used_in\": [\"inland\"], \"enum\": [\"W\", \"M\", \"C\", \"S\", \"MH\"], \"aliases\": [\"general_building_type\", \"bldgtype\", \"generalbuildingtype\"] }, \"eq_building_type\": { \"type\": \"string\", \"description\": \"Earthquake-specific building type classification\", \"required\": true, \"nullable\": false, \"used_in\": [\"earthquake\"], \"aliases\": [\"eqbldgtypeid\", \"eq_building_type\", \"earthquake_building_type\"] }, \"eq_design_level\": { \"type\": \"string\", \"description\": \"Earthquake design level classification\", \"required\": true, \"nullable\": false, \"used_in\": [\"earthquake\"], \"aliases\": [\"eqdesignlevelid\", \"eq_design_level\", \"design_level\"] } } } National Structures Inventory (NSI) \u00b6 The National Structures Inventory (NSI) , developed by the U.S. Army Corps of Engineers (USACE) , is a nationwide database of structures across the 50 U.S. states. At present, the NSI does not include coverage for U.S. territories. The publicly available NSI dataset provided many of the key fields used for consequence analysis; however, it is important to note that building and contents values are reported as depreciated values rather than full replacement costs. Full technical documentation for the NSI is available on the USACE NSI Technical Documentation page . USACE also maintains a restricted version of the NSI accessible to federal users, which contains additional attributes derived from parcel data and other proprietary sources. To support national hazard risk assessments, FEMA has developed an enhanced internal version of the NSI that extends coverage to the District of Columbia , Puerto Rico , the U.S. Virgin Islands , and Pacific Territories . This FEMA-enhanced dataset applies full replacement values consistent with the Hazus 7.0 Inventory Technical Manual and resolves several known data quality issues identified in the public NSI. NSI 2022 Public Version \u00b6 The 2022 Public NSI contains all attributes required to support both inland and coastal consequence modeling. Table 2 lists the key fields used in the Consequence Modeling Solution, including data types, assumptions, rules, and default values assigned when data is missing. Table 2. NSI 2022 Public Data Attributes for Analysis Analysis Attribute Data Type NSI Field Name Consequence Modeling Assumption Rule Default if Missing Geometry Point Shape Inland, Coastal Point geometry Must be valid point geometry Error (required) Unique ID Object ID fid Inland, Coastal Provided Must be present and unique Error (required) Occupancy Type String occtype Inland, Coastal Provided; must map to Hazus types Must map to Hazus types RES1 Building Value Numeric val_struct Inland, Coastal Depreciated USD value Must be present Error (required) Content Value Numeric val_cont Inland, Coastal Depreciated USD value Validate > 0; assign default if missing Default % by occupancy (see Inventory Methodology Table 3) Number of Stories Numeric num_story Inland, Coastal Provided Validate > 0; assign default 1 Area / Square Footage Numeric sqft Inland Square footage Validate > 0; assign default Hazus defaults (Inventory Methodology Table 2) General Building Type String bldgtype Inland Provided (M, W, H, S) Assign default if missing W (Wood) Foundation Type String found_type Inland, Coastal Provided (C, B, S, P, I, F, W) Assign default if missing Slab Foundation Height Numeric found_ht Inland, Coastal Feet above ground Assign default Slab = 1 ft; Shallow = 3 ft; Pile = 8 ft; Basement = 2 ft Ground Elevation Numeric Ground_elv Coastal Feet (NAVD88) Required for coastal modeling Error (required) NSI 2022 Public \u2013 Inland Foundation Type Mapping \u00b6 For the NSI Public dataset, the found_type field must be mapped to the standardized inland foundation types used by the Consequence Modeling engine. Implementation Rules: The NSI found_type field is always used as the source field. Foundation types must be translated using Table 3 . If a code does not match a supported value: Treat the foundation type as uncertain , and Assign the default inland foundation type SLAB . No parcel-derived refinements are available in the public NSI. Table 3. Inland Foundation Type Mapping for NSI 2022 Public Version found_type Description Assigned Inland Foundation Type C Crawl SHAL B Basement BASE S Slab SLAB P Pier SHAL F Fill SLAB W Solid Wall SHAL I Pile PILE NSI 2022 Public \u2013 Coastal Foundation Type Mapping \u00b6 TODO: Define coastal foundation type mapping rules for the NSI Public dataset. NSI 2022 FEMA-Enhanced Version \u00b6 The NSI 2022 FEMA-Enhanced Version allows users to calculate losses using full replacement costs and expands structure coverage to include Washington, D.C., Puerto Rico, U.S. Virgin Islands. This enhanced version also includes parcel-derived fields that support refinement of the inland foundation type assignment. However, the FEMA-enhanced dataset does not include ground-elevation information. As a result, only inland consequence modeling is supported out of the box. Users may preprocess the dataset and manually supply ground elevations if they wish to perform coastal modeling using the user-defined inventory ingestion process . Table 4 summarizes the attributes used in the analysis, including data types, assumptions, rules, and defaults applied when values are missing. Table 4. NSI 2022 FEMA-Enhanced Data Attributes for Analysis Analysis Attribute Data Type NSI Field Name Assumption Rule Default if Missing Geometry Point Shape Point geometry Must be valid point geometry Error (required) Unique ID Object ID OBJECTID Provided Must be present and unique Error (required) Occupancy Type String OCCTYPE Provided; must map to Hazus occupancy types Must map to Hazus types RES1 Building Value Numeric Hazus_Building_Values Full replacement cost (USD) Must be present Error (required) Content Value Numeric Hazus_Content_Values Full replacement cost (USD) Validate > 0; assign default if missing Default % by occupancy (Inventory Methodology Table 3) Number of Stories Numeric NUM_STORY Provided Validate > 0; assign default 1 Area / Square Footage Numeric SQFT Square footage (sq ft) Validate > 0; assign default Hazus defaults (Inventory Methodology Table 2) General Building Type String GENERALBUILDINGTYPE Provided (M, W, H, S) Assign default if missing W (Wood) Foundation Type String FNDTYPE Provided (C, B, S, P, I, F, W) Assign default if missing Slab Foundation Height Numeric FOUND_HT Feet above ground elevation Assign default if missing Slab = 1 ft; Shallow = 3 ft; Pile = 8 ft; Basement = 2 ft Foundation Type (Parcel) String P_FNDTYPE Provided Used only for parcel-based refinement logic None Basement Type (Parcel) String P_BSMNT Provided Used only for parcel-based refinement logic None NSI 2022 FEMA-Enhanced \u2014 Inland Foundation Type Mapping \u00b6 For the FEMA-Enhanced NSI, parcel-derived fields ( P_FNDTYPE and P_BSMNT ) are used to refine the inland foundation type. The following rules determine the assigned inland foundation type : Refinement Rules: If P_BSMNT contains any of the following codes \u2014 B , U , I , F , P , L , D , Y \u2014 set inland foundation type to BASE . If P_FNDTYPE contains any of the following codes \u2014 S , P , L , F , E , T , W , A \u2014 inland foundation type must stay blank/null , even when P_BSMNT indicates a basement. If P_BSMNT does not indicate a basement, inland foundation type comes directly from P_FNDTYPE using the mapping in Table 5 . If P_FNDTYPE is null, use the NSI-provided FNDTYPE field and map it using the same rules as the NSI 2022 Public Version ( found_type ). FNDTYPE in FEMA-Enhanced is equivalent to found_type in the Public NSI. Table 5. NSI 2022 FEMA-Enhanced Parcel Foundation Type Mapping P_FNDTYPE Description Assigned Inland Foundation Type P Piers SHAL A Concrete SLAB W Wood SHAL C Crossed Walls SLAB S Slab SLAB K Concrete Block SHAL O Other NULL G Stone SHAL D Masonry SHAL L Piling PILE R Retaining Wall SHAL T Footing SLAB B Crawl / Raised SHAL F Mud Sill SLAB E Earth SLAB Z Placeholder If P_BSMNT indicates basement \u2192 BASE , otherwise Slab NSI Data Schema: \u00b6 { \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"$id\": \"https://example.com/schemas/nsi_schema.json\", \"title\": \"NSI Buildings Schema\", \"version\": \"0.1.0\", \"description\": \"Schema for NSI (National Structure Inventory) building data\", \"default fields\": { \"target_fid\": { \"type\": \"string\", \"description\": \"Unique identifier for the building\", \"default target field\": \"id\", \"required\": true, \"nullable\": false }, \"occtype\": { \"type\": \"string\", \"description\": \"Occupancy type code (e.g., RES1, COM1)\", \"default target field\": \"occupancy_type\", \"required\": false, \"nullable\": true }, \"found_ht\": { \"type\": \"number\", \"description\": \"First floor height (feet above ground)\", \"default target field\": \"first_floor_height\", \"required\": false, \"nullable\": true }, \"found_type\": { \"type\": \"string\", \"description\": \"Foundation type code (I=Pile, P=Pier, W=Solid Wall, B=Basement, C=Crawl, F=Fill, S=Slab)\", \"default target field\": \"foundation_type\", \"enum\": [\"I\", \"P\", \"W\", \"B\", \"C\", \"F\", \"S\"], \"required\": false, \"nullable\": true }, \"num_story\": { \"type\": \"number\", \"description\": \"Number of stories in the building\", \"default target field\": \"number_stories\", \"required\": true, \"nullable\": false }, \"sqft\": { \"type\": \"number\", \"description\": \"Building area in square feet\", \"default target field\": \"area\", \"required\": true, \"nullable\": false }, \"val_struct\": { \"type\": \"number\", \"description\": \"Building replacement cost ($USD)\", \"default target field\": \"building_cost\", \"required\": true, \"nullable\": false }, \"val_cont\": { \"type\": \"number\", \"description\": \"Contents replacement cost ($USD)\", \"default target field\": \"content_cost\", \"required\": false, \"nullable\": true }, \"bldgtype\": { \"type\": \"string\", \"description\": \"General building type code (e.g., W=Wood, M=Masonry, C=Concrete, S=Steel)\", \"default target field\": \"general_building_type\", \"required\": false, \"nullable\": true } } } However, users may provide a crosswalk (a.k.a. override) from the target fields to the user's non-standard fields. Example of User-Provided Override for NSI Field Names: (keys=target_field, values=user's field) { \"building_cost\": \"my_custom_building_cost_field\" } Milliman Market Baskets Data \u00b6 The Milliman Market Baskets were developed by Milliman, Inc. to support FEMA\u2019s Risk Rating 2.0 initiative . Milliman created Market Baskets for all U.S. states and territories to provide a representative sample of single-family homes (RES1) used in the development of rating factors. Market Basket locations were derived primarily from CoreLogic ParcelPoint data, supplemented with U.S. Census and National Hydrography Dataset (NHD) information, and refined through extensive quality control to ensure accuracy and realistic spatial distribution. Three categories of data, referred to as \u201cbooks\u201d , were created from the Market Baskets: Uniform Book \u2013 Each property assigned identical structural and coverage characteristics, allowing geographic variability to be analyzed independently. Uncorrelated Market Basket \u2013 Contains randomized property and policy characteristics not correlated with geography; foundation type and first-floor height remain linked to prevent implausible combinations. Correlated Market Basket (Inforce Dataset) \u2013 Joined with FEMA policy data (GFE access required); attributes are correlated to reflect realistic joint distributions and align with observed parcel and NFIP exposure data. The Consequences Solution is designed and tested using the Uniform and Uncorrelated Market Basket datasets. Table 6 describes the analysis attributes used across these books. Although the schema is consistent, the method of attribute imputation varies by dataset. For example, the Uncorrelated Market Basket randomizes property and coverage characteristics, while the Correlated Market Basket applies state-specific distributions to more closely represent actual conditions. The Milliman Market Basket datasets support both coastal and inland loss calculations, as they include the necessary structural, coverage, and geographic attributes for each modeling environment. Their use, however, is limited to single-family residential (RES1) structures, as the datasets were specifically developed for rating factor development under FEMA\u2019s NFIP framework. For more details, refer to the FEMA (2022) . Table 6. Milliman Data Attributes for Analysis Analysis Attribute NSI Field Name Data Type Notes X Location LON Double Y Location LAT Double Unique ID Location String Occupancy Type -- -- All points are RES1 Building Value BLDG_VALUE Long Full replacement value Building Insurance Deductible BLDG_DED Long Building Insurance Limit BLDG_LIMIT Long Content Value CNT_VALUE Long Full replacement value Content Insurance Deductible CNT_DED Long Content Insurance Limit CNT_LIMIT Long Number of Stories NUM_STORIES Long Area/Square Footage -- -- Use default area for RES1 based on Hazus Methodolgy, i.e. sqft=1800 General Building Type CONSTR_CODE Long Construction type, ( 1 = W, 2 = M), Use default value W if not provided. Foundation Type foundationtype Long Foundation type, (2 = basement; 4 = crawlspace; 6 = pier; 7 = fill or wall; 8 = slab; 9 = pile) Foundation Height FIRST_FLOOR_ELEV Long First floor height (feet above ground) Basement Type BasementFinishType Long Basement Finish type, (0 = no basement; 1 = unfinished basement; 2 = finished basement) Ground Elevation elev_ft Float Digital Elevation Model (DEM) (ground) elevation (feet NAVD88) Milliman \u2014 Inland Foundation Type Mapping \u00b6 For both the Uniform Book and Uncorrelated Market Basket datasets, the foundation field contains numeric codes that must be mapped to inland foundation types used by the Consequences Solution. These mappings support correct depth\u2013damage function assignment. Table 7. Milliman Inland Foundation Type Mapping foundation Description Assigned Inland Foundation Type 2 Basement BASE 4 Crawlspace SHAL 6 Pier SHAL 7 Fill / Wall SLAB 8 Slab SLAB 9 Pile PILE Milliman \u2014 Coastal Foundation Type Mapping \u00b6 To be developed. Milliman Data Schema: \u00b6 { \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"$id\": \"https://example.com/schemas/milliman_schema.json\", \"title\": \"Milliman Buildings Schema\", \"version\": \"0.2.0\", \"description\": \"Typical schema for Milliman building data (Uniform, Uncorrelated Market Basket)\", \"default fields\": { \"accntnum\": { \"type\": \"number\", \"description\": \"unique policy id (0 prefix=market basket, 1 prefix=uncorrelated book, no prefix=uniform book)\", \"default target field\": null, \"required\": false, \"nullable\": true }, \"location\": { \"type\": \"string\", \"description\": \"Location ID of building which serves as the unique identifier\", \"default target field\": \"id\", \"required\": true, \"nullable\": false }, \"BLDG_DED\": { \"type\": \"number\", \"description\": \"Building insurance deductible ($USD)\", \"default target field\": null, \"required\": false, \"nullable\": true }, \"BLDG_LIMIT\": { \"type\": \"number\", \"description\": \"Building insurance limit ($USD)\", \"default target field\": null, \"required\": false, \"nullable\": true }, \"CNT_DED\": { \"type\": \"number\", \"description\": \"Contents insurance deductible ($USD)\", \"default target field\": null, \"required\": false, \"nullable\": true }, \"CNT_LIMIT\": { \"type\": \"number\", \"description\": \"Contents insurance limit ($USD)\", \"default target field\": null, \"required\": false, \"nullable\": true }, \"STATE\": { \"type\": \"string\", \"description\": \"Two-letter state abbreviation\", \"default target field\": null, \"required\": false, \"nullable\": true }, \"POSTCODE\": { \"type\": \"string\", \"description\": \"5-digit ZIP code\", \"default target field\": null, \"required\": false, \"nullable\": true }, \"COUNTRY\": { \"type\": \"string\", \"description\": \"Country code (e.g., US)\", \"default target field\": null, \"required\": false, \"nullable\": true }, \"LON\": { \"type\": \"number\", \"description\": \"Longitude in decimal degrees\", \"default target field\": null, \"required\": true, \"nullable\": false }, \"LAT\": { \"type\": \"number\", \"description\": \"Latitude in decimal degrees\", \"default target field\": null, \"required\": true, \"nullable\": false }, \"BLDG_VALUE\": { \"type\": \"number\", \"description\": \"Building replacement cost ($USD)\", \"default target field\": \"building_cost\", \"required\": true, \"nullable\": false }, \"CNT_VALUE\": { \"type\": \"number\", \"description\": \"Contents replacement cost ($USD)\", \"default target field\": \"content_cost\", \"required\": true, \"nullable\": false }, \"CONSTR_CODE\": { \"type\": \"number\", \"description\": \"Construction type code (1=wood; 2=masonry)\", \"default target field\": \"general_building_type\", \"enum\": [1, 2], \"required\": false, \"nullable\": true }, \"NUM_STORIES\": { \"type\": \"number\", \"description\": \"Number of stories in the building\", \"default target field\": \"number_stories\", \"required\": true, \"nullable\": false }, \"YEAR_BUILT\": { \"type\": \"number\", \"description\": \"Year the building was constructed\", \"default target field\": null, \"required\": false, \"nullable\": true }, \"FoundationType\": { \"type\": \"number\", \"description\": \"Foundation type code (2=basement; 4=crawlspace; 6=pier; 7=fill or wall; 8=slab; 9=pile)\", \"default target field\": \"foundation_type\", \"enum\": [2, 4, 6, 7, 8, 9], \"required\": false, \"nullable\": true }, \"BasementFinishType\": { \"type\": \"number\", \"description\": \"Basement finish type code (0=no basement; 1=unfinished basement; 2=finished basement)\", \"default target field\": null, \"enum\": [0, 1, 2], \"required\": false, \"nullable\": true }, \"FIRST_FLOOR_ELEV\": { \"type\": \"number\", \"description\": \"First floor elevation above ground in\", \"default target field\": \"first_floor_height\", \"required\": true, \"nullable\": false }, \"BASE_FLOOD_ELEV\": { \"type\": \"number\", \"description\": \"Base flood elevation (BFE) in feet\", \"default target field\": null, \"required\": false, \"nullable\": true } } } However, users may provide a crosswalk (a.k.a. override) from the target fields to the user's non-standard fields. Example of User-Provided Override for Milliman Field Names: (keys=target_field, values=user's field) { \"building_cost\": \"my_custom_building_cost_field\" } User Defined Data \u00b6 Users can provide custom building inventories for consequence analysis by ensuring their data conforms to the Base Buildings Schema defined above. The Buildings class provides flexible ingestion pathways that support various data formats and field naming conventions. Requirements for User-Defined Inventories \u00b6 Geometry : Must include valid point geometry (latitude/longitude coordinates) Required Fields : Must contain or allow imputation of: Unique building identifier ( id ) Number of stories ( number_stories ) Building floor area ( area ) Building replacement cost ( building_cost ) Optional Fields : May include (or rely on defaults): Occupancy type, foundation type, first floor height Content cost, inventory cost, construction type Any output fields from previous analyses Field Mapping Approaches \u00b6 Approach 1: Use Standard Field Names Create a GeoDataFrame with columns matching target field names or their aliases: import geopandas as gpd import pandas as pd from inland_consequences.buildings import Buildings # Create DataFrame with standard field names data = { 'id': ['B001', 'B002', 'B003'], 'occupancy_type': ['RES1', 'COM1', 'IND2'], 'building_cost': [250000, 500000, 1000000], 'content_cost': [125000, 500000, 1500000], 'number_stories': [2, 1, 3], 'area': [2000, 5000, 10000], 'first_floor_height': [1.0, 2.0, 3.0], 'foundation_type': ['S', 'S', 'B'], 'general_building_type': ['W', 'M', 'C'], 'latitude': [40.7, 40.8, 40.9], 'longitude': [-74.0, -74.1, -74.2] } # Create GeoDataFrame with point geometry gdf = gpd.GeoDataFrame( data, geometry=gpd.points_from_xy(data['longitude'], data['latitude']), crs='EPSG:4326' ) # No overrides needed - fields auto-detected buildings = Buildings(gdf) Approach 2: Provide Field Overrides Map your custom field names to target fields using the overrides parameter: # User has non-standard field names data = { 'building_id': ['B001', 'B002', 'B003'], 'use_code': ['RES1', 'COM1', 'IND2'], 'struct_value': [250000, 500000, 1000000], 'contents_value': [125000, 500000, 1500000], 'floors': [2, 1, 3], 'sqft': [2000, 5000, 10000], 'ffh_ft': [1.0, 2.0, 3.0], 'foundation': ['SLAB', 'SLAB', 'BASEMENT'], 'construction': ['WOOD', 'MASONRY', 'CONCRETE'], 'lat': [40.7, 40.8, 40.9], 'lon': [-74.0, -74.1, -74.2] } gdf = gpd.GeoDataFrame( data, geometry=gpd.points_from_xy(data['lon'], data['lat']), crs='EPSG:4326' ) # Provide explicit mapping from target fields to user's fields overrides = { 'id': 'building_id', 'occupancy_type': 'use_code', 'building_cost': 'struct_value', 'content_cost': 'contents_value', 'number_stories': 'floors', 'area': 'sqft', 'first_floor_height': 'ffh_ft', 'foundation_type': 'foundation', 'general_building_type': 'construction' } buildings = Buildings(gdf, overrides=overrides) Approach 3: Rely on Default Imputation Provide only required fields; optional fields will be imputed using documented defaults: # Minimal dataset - only required fields data = { 'building_id': ['B001', 'B002', 'B003'], 'building_cost': [250000, 500000, 1000000], 'number_stories': [2, 1, 3], 'area': [2000, 5000, 10000], 'latitude': [40.7, 40.8, 40.9], 'longitude': [-74.0, -74.1, -74.2] } gdf = gpd.GeoDataFrame( data, geometry=gpd.points_from_xy(data['longitude'], data['latitude']), crs='EPSG:4326' ) overrides = {'id': 'building_id'} # Optional fields will be imputed: # - occupancy_type: RES1 # - foundation_type: S (Slab) # - first_floor_height: 1.0 ft (slab default) # - general_building_type: W (Wood) # - content_cost: 50% of building_cost (RES1 default) buildings = Buildings(gdf, overrides=overrides) Foundation Type Coding \u00b6 If your data uses different foundation type codes than the standardized codes (I, P, W, B, C, F, S), you must preprocess your data to translate to the standard codes: Standard Code Description Inland Foundation Type I Pile (Infilled) PILE P Pier/Post SHAL (Shallow) W Solid Wall SHAL (Shallow) B Basement BASE (Basement) C Crawlspace SHAL (Shallow) F Fill SLAB S Slab on Grade SLAB Data Validation \u00b6 The Buildings class performs automatic validation: Required fields present : Verifies all required fields exist (either directly or through aliases) No missing required values : Ensures required fields have no NULL/NaN values Valid geometry : Confirms point geometry is valid and has a coordinate reference system If validation fails, the class raises descriptive errors indicating which fields are missing or invalid. Example: Complete User-Defined Workflow \u00b6 from inland_consequences.buildings import Buildings from inland_consequences.inland_flood_analysis import InlandFloodAnalysis from inland_consequences.raster_collection import RasterCollection from inland_consequences.default_vulnerability import DefaultVulnerability # 1. Load user's building data user_buildings_gdf = gpd.read_file('my_buildings.gpkg') # 2. Define field mappings field_overrides = { 'id': 'UNIQUE_ID', 'occupancy_type': 'OCCUPANCY', 'building_cost': 'REPLACEMENT_VALUE', 'number_stories': 'NUM_FLOORS', 'area': 'FLOOR_AREA_SQFT' } # 3. Create Buildings object (auto-validates and imputes defaults) buildings = Buildings(user_buildings_gdf, overrides=field_overrides) # 4. Use in analysis hazard_rasters = RasterCollection('flood_depth_*.tif') vulnerability = DefaultVulnerability() with InlandFloodAnalysis(hazard_rasters, buildings, vulnerability) as analysis: analysis.calculate_losses() results_gdf = analysis.buildings.gdf # GeoDataFrame with loss results For additional guidance on default values and imputation strategies, see the Inventory Methodology Documentation .","title":"Building Inventories Technical Implementation"},{"location":"building_inventories/#building-inventories-technical-implementation","text":"The Consequence Modeling Solution is designed to natively ingest the National Structures Inventory (NSI) and the Milliman Market Basket datasets out of the box, while also providing a pathway for users to integrate their own custom inventory data . Table 1 identifies the supported data sources, versions, expected input formats, and applicable consequence-modeling pathways. Table 1. Supported Inventory Data Sources Data Source Version Input File Type Consequence Modeling NSI 2022 Public Version GeoPackage Inland, Coastal NSI 2022 FEMA-Enhanced Version File Geodatabase Inland only Milliman Market Baskets 2021 Uniform, Uncorrelated Comma-Separated Values (CSV) Inland, Coastal User-defined Inventories User-defined User-defined Inland, Coastal For additional details on inventory requirements and methodology, refer to the Inventory Methodology Documentation .","title":"Building Inventories Technical Implementation"},{"location":"building_inventories/#inventory-ingestion-and-processing-approach","text":"Regardless of which inventory type is provided, several required fields must be present to support loss calculations. However, the Consequence Solution is designed to minimize the amount of data preprocessing required from the user by implementing the following strategies: Auto-detection of required fields based on common naming conventions Auto-population of missing fields using documented default values User-provided overrides for NSI and Milliman field names Comprehensive documentation for each inventory source, including requirements for user-defined datasets Schema validation to ensure completeness and correctness prior to modeling","title":"Inventory Ingestion and Processing Approach"},{"location":"building_inventories/#base-buildings-class","text":"The Base Buildings Class provides standardized field mapping for building inventories. It defines target fields that all consequence analysis operations use, but does not validate or impute missing fields . The base class simply maps source field names (via auto-detection or explicit overrides) to standardized target field names. Subclasses extend the base class with schema validation and field imputation: NsiBuildings : Validates NSI required fields and imputes optional fields using NSI-specific defaults MillimanBuildings : Validates Milliman required fields and imputes optional fields (including creating fields not present in source data like occupancy_type and area ) User-defined : Can use base Buildings class directly (requires all fields present) or create a custom subclass with validation/imputation The Buildings class provides flexible field mapping through: Automatic field detection using case-insensitive matching against common aliases Explicit field overrides for non-standard field names Property-based access to all target fields regardless of source naming","title":"Base Buildings Class"},{"location":"building_inventories/#base-buildings-schema","text":"The following schema defines all target fields used by the Consequence Modeling Solution. Table 1 provides a summary of the target fields, their data types, and usage context. Table 1. Base Buildings Target Fields Target Field Data Type Description Used In Common Aliases id String Unique identifier for the building Inland, Coastal id, building_id, bldg_id, fd_id occupancy_type String HAZUS occupancy classification (e.g., RES1, COM1, IND2) Inland, Coastal occupancy_type, occtype, occupancy, occ_type, building_type first_floor_height Numeric First floor height above ground elevation (feet) Inland, Coastal first_floor_height, found_ht, first_floor_ht, ffh, floor_height foundation_type String Foundation type code (BASE, PILE, SHAL, SLAB) Inland, Coastal foundation_type, fndtype, found_type, fnd_type number_stories Numeric Number of stories (floors) in the building Inland, Coastal number_stories, num_story, numstories, stories, num_floors area Numeric Building floor area (square feet) Inland, Coastal area, sqft, building_area, floor_area building_cost Numeric Building structural replacement cost (USD) Inland, Coastal buildingcostusd, building_cost, val_struct, cost, building_value content_cost Numeric Contents replacement cost (USD) Inland, Coastal contentcostusd, content_cost, val_cont, contents_cost inventory_cost Numeric Business inventory replacement cost (USD) Inland, Coastal inventorycostusd, inventory_cost, val_inv, inv_cost general_building_type String Construction material code (W, M, C, S, MH) Inland general_building_type, bldgtype, generalbuildingtype eq_building_type String Earthquake-specific building type classification Earthquake eqbldgtypeid, eq_building_type, earthquake_building_type eq_design_level String Earthquake design level classification Earthquake eqdesignlevelid, eq_design_level, design_level","title":"Base Buildings Schema"},{"location":"building_inventories/#base-buildings-data-schema","text":"{ \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"$id\": \"https://example.com/schemas/buildings_schema.json\", \"title\": \"Base Buildings Schema\", \"version\": \"0.1.0\", \"description\": \"Base schema defining standardized target fields for building inventories. The base Buildings class performs field mapping only. Specific implementations (NsiBuildings, MillimanBuildings) extend the base class with schema validation and field imputation. The 'required' attribute indicates whether a field must be present for consequence analysis, not whether the base class validates it.\", \"target fields\": { \"id\": { \"type\": \"string\", \"description\": \"Unique identifier for the building\", \"required\": true, \"nullable\": false, \"used_in\": [\"inland\", \"coastal\"], \"aliases\": [\"id\", \"building_id\", \"bldg_id\", \"fd_id\"] }, \"occupancy_type\": { \"type\": \"string\", \"description\": \"Occupancy type code following HAZUS classification (e.g., RES1, COM1, IND2)\", \"required\": true, \"nullable\": false, \"used_in\": [\"inland\", \"coastal\"], \"aliases\": [\"occupancy_type\", \"occtype\", \"occupancy\", \"occ_type\", \"building_type\"] }, \"first_floor_height\": { \"type\": \"number\", \"description\": \"First floor height above ground elevation (feet)\", \"required\": true, \"nullable\": false, \"used_in\": [\"inland\", \"coastal\"], \"aliases\": [\"first_floor_height\", \"found_ht\", \"first_floor_ht\", \"ffh\", \"floor_height\"] }, \"foundation_type\": { \"type\": \"string\", \"description\": \"Foundation type code for inland flood modeling (I=Pile, P=Pier, W=Solid Wall, B=Basement, C=Crawl, F=Fill, S=Slab)\", \"required\": true, \"nullable\": false, \"used_in\": [\"inland\", \"coastal\"], \"enum\": [\"I\", \"P\", \"W\", \"B\", \"C\", \"F\", \"S\"], \"aliases\": [\"foundation_type\", \"fndtype\", \"found_type\", \"fnd_type\"] }, \"number_stories\": { \"type\": \"number\", \"description\": \"Number of stories (floors) in the building\", \"required\": true, \"nullable\": false, \"used_in\": [\"inland\", \"coastal\"], \"aliases\": [\"number_stories\", \"num_story\", \"numstories\", \"stories\", \"num_floors\", \"floors\"] }, \"area\": { \"type\": \"number\", \"description\": \"Building floor area in square feet\", \"required\": true, \"nullable\": false, \"used_in\": [\"inland\", \"coastal\"], \"aliases\": [\"area\", \"sqft\", \"building_area\", \"floor_area\"] }, \"building_cost\": { \"type\": \"number\", \"description\": \"Building structural replacement cost in US dollars\", \"required\": true, \"nullable\": false, \"used_in\": [\"inland\", \"coastal\"], \"aliases\": [\"buildingcostusd\", \"building_cost\", \"val_struct\", \"cost\", \"replacement_cost\", \"building_value\"] }, \"content_cost\": { \"type\": \"number\", \"description\": \"Contents replacement cost in US dollars\", \"required\": true, \"nullable\": false, \"used_in\": [\"inland\", \"coastal\"], \"aliases\": [\"contentcostusd\", \"content_cost\", \"val_cont\", \"contents_cost\"] }, \"inventory_cost\": { \"type\": \"number\", \"description\": \"Business inventory replacement cost in US dollars\", \"required\": true, \"nullable\": false, \"used_in\": [\"inland\", \"coastal\"], \"aliases\": [\"inventorycostusd\", \"inventory_cost\", \"val_inv\", \"inv_cost\"] }, \"general_building_type\": { \"type\": \"string\", \"description\": \"General construction type code (W=Wood, M=Masonry, C=Concrete, S=Steel, MH=Manufactured Housing)\", \"required\": true, \"nullable\": false, \"used_in\": [\"inland\"], \"enum\": [\"W\", \"M\", \"C\", \"S\", \"MH\"], \"aliases\": [\"general_building_type\", \"bldgtype\", \"generalbuildingtype\"] }, \"eq_building_type\": { \"type\": \"string\", \"description\": \"Earthquake-specific building type classification\", \"required\": true, \"nullable\": false, \"used_in\": [\"earthquake\"], \"aliases\": [\"eqbldgtypeid\", \"eq_building_type\", \"earthquake_building_type\"] }, \"eq_design_level\": { \"type\": \"string\", \"description\": \"Earthquake design level classification\", \"required\": true, \"nullable\": false, \"used_in\": [\"earthquake\"], \"aliases\": [\"eqdesignlevelid\", \"eq_design_level\", \"design_level\"] } } }","title":"Base Buildings Data Schema:"},{"location":"building_inventories/#national-structures-inventory-nsi","text":"The National Structures Inventory (NSI) , developed by the U.S. Army Corps of Engineers (USACE) , is a nationwide database of structures across the 50 U.S. states. At present, the NSI does not include coverage for U.S. territories. The publicly available NSI dataset provided many of the key fields used for consequence analysis; however, it is important to note that building and contents values are reported as depreciated values rather than full replacement costs. Full technical documentation for the NSI is available on the USACE NSI Technical Documentation page . USACE also maintains a restricted version of the NSI accessible to federal users, which contains additional attributes derived from parcel data and other proprietary sources. To support national hazard risk assessments, FEMA has developed an enhanced internal version of the NSI that extends coverage to the District of Columbia , Puerto Rico , the U.S. Virgin Islands , and Pacific Territories . This FEMA-enhanced dataset applies full replacement values consistent with the Hazus 7.0 Inventory Technical Manual and resolves several known data quality issues identified in the public NSI.","title":"National Structures Inventory (NSI)"},{"location":"building_inventories/#nsi-2022-public-version","text":"The 2022 Public NSI contains all attributes required to support both inland and coastal consequence modeling. Table 2 lists the key fields used in the Consequence Modeling Solution, including data types, assumptions, rules, and default values assigned when data is missing. Table 2. NSI 2022 Public Data Attributes for Analysis Analysis Attribute Data Type NSI Field Name Consequence Modeling Assumption Rule Default if Missing Geometry Point Shape Inland, Coastal Point geometry Must be valid point geometry Error (required) Unique ID Object ID fid Inland, Coastal Provided Must be present and unique Error (required) Occupancy Type String occtype Inland, Coastal Provided; must map to Hazus types Must map to Hazus types RES1 Building Value Numeric val_struct Inland, Coastal Depreciated USD value Must be present Error (required) Content Value Numeric val_cont Inland, Coastal Depreciated USD value Validate > 0; assign default if missing Default % by occupancy (see Inventory Methodology Table 3) Number of Stories Numeric num_story Inland, Coastal Provided Validate > 0; assign default 1 Area / Square Footage Numeric sqft Inland Square footage Validate > 0; assign default Hazus defaults (Inventory Methodology Table 2) General Building Type String bldgtype Inland Provided (M, W, H, S) Assign default if missing W (Wood) Foundation Type String found_type Inland, Coastal Provided (C, B, S, P, I, F, W) Assign default if missing Slab Foundation Height Numeric found_ht Inland, Coastal Feet above ground Assign default Slab = 1 ft; Shallow = 3 ft; Pile = 8 ft; Basement = 2 ft Ground Elevation Numeric Ground_elv Coastal Feet (NAVD88) Required for coastal modeling Error (required)","title":"NSI 2022 Public Version"},{"location":"building_inventories/#nsi-2022-public-inland-foundation-type-mapping","text":"For the NSI Public dataset, the found_type field must be mapped to the standardized inland foundation types used by the Consequence Modeling engine. Implementation Rules: The NSI found_type field is always used as the source field. Foundation types must be translated using Table 3 . If a code does not match a supported value: Treat the foundation type as uncertain , and Assign the default inland foundation type SLAB . No parcel-derived refinements are available in the public NSI. Table 3. Inland Foundation Type Mapping for NSI 2022 Public Version found_type Description Assigned Inland Foundation Type C Crawl SHAL B Basement BASE S Slab SLAB P Pier SHAL F Fill SLAB W Solid Wall SHAL I Pile PILE","title":"NSI 2022 Public \u2013 Inland Foundation Type Mapping"},{"location":"building_inventories/#nsi-2022-public-coastal-foundation-type-mapping","text":"TODO: Define coastal foundation type mapping rules for the NSI Public dataset.","title":"NSI 2022 Public \u2013 Coastal Foundation Type Mapping"},{"location":"building_inventories/#nsi-2022-fema-enhanced-version","text":"The NSI 2022 FEMA-Enhanced Version allows users to calculate losses using full replacement costs and expands structure coverage to include Washington, D.C., Puerto Rico, U.S. Virgin Islands. This enhanced version also includes parcel-derived fields that support refinement of the inland foundation type assignment. However, the FEMA-enhanced dataset does not include ground-elevation information. As a result, only inland consequence modeling is supported out of the box. Users may preprocess the dataset and manually supply ground elevations if they wish to perform coastal modeling using the user-defined inventory ingestion process . Table 4 summarizes the attributes used in the analysis, including data types, assumptions, rules, and defaults applied when values are missing. Table 4. NSI 2022 FEMA-Enhanced Data Attributes for Analysis Analysis Attribute Data Type NSI Field Name Assumption Rule Default if Missing Geometry Point Shape Point geometry Must be valid point geometry Error (required) Unique ID Object ID OBJECTID Provided Must be present and unique Error (required) Occupancy Type String OCCTYPE Provided; must map to Hazus occupancy types Must map to Hazus types RES1 Building Value Numeric Hazus_Building_Values Full replacement cost (USD) Must be present Error (required) Content Value Numeric Hazus_Content_Values Full replacement cost (USD) Validate > 0; assign default if missing Default % by occupancy (Inventory Methodology Table 3) Number of Stories Numeric NUM_STORY Provided Validate > 0; assign default 1 Area / Square Footage Numeric SQFT Square footage (sq ft) Validate > 0; assign default Hazus defaults (Inventory Methodology Table 2) General Building Type String GENERALBUILDINGTYPE Provided (M, W, H, S) Assign default if missing W (Wood) Foundation Type String FNDTYPE Provided (C, B, S, P, I, F, W) Assign default if missing Slab Foundation Height Numeric FOUND_HT Feet above ground elevation Assign default if missing Slab = 1 ft; Shallow = 3 ft; Pile = 8 ft; Basement = 2 ft Foundation Type (Parcel) String P_FNDTYPE Provided Used only for parcel-based refinement logic None Basement Type (Parcel) String P_BSMNT Provided Used only for parcel-based refinement logic None","title":"NSI 2022 FEMA-Enhanced Version"},{"location":"building_inventories/#nsi-2022-fema-enhanced-inland-foundation-type-mapping","text":"For the FEMA-Enhanced NSI, parcel-derived fields ( P_FNDTYPE and P_BSMNT ) are used to refine the inland foundation type. The following rules determine the assigned inland foundation type : Refinement Rules: If P_BSMNT contains any of the following codes \u2014 B , U , I , F , P , L , D , Y \u2014 set inland foundation type to BASE . If P_FNDTYPE contains any of the following codes \u2014 S , P , L , F , E , T , W , A \u2014 inland foundation type must stay blank/null , even when P_BSMNT indicates a basement. If P_BSMNT does not indicate a basement, inland foundation type comes directly from P_FNDTYPE using the mapping in Table 5 . If P_FNDTYPE is null, use the NSI-provided FNDTYPE field and map it using the same rules as the NSI 2022 Public Version ( found_type ). FNDTYPE in FEMA-Enhanced is equivalent to found_type in the Public NSI. Table 5. NSI 2022 FEMA-Enhanced Parcel Foundation Type Mapping P_FNDTYPE Description Assigned Inland Foundation Type P Piers SHAL A Concrete SLAB W Wood SHAL C Crossed Walls SLAB S Slab SLAB K Concrete Block SHAL O Other NULL G Stone SHAL D Masonry SHAL L Piling PILE R Retaining Wall SHAL T Footing SLAB B Crawl / Raised SHAL F Mud Sill SLAB E Earth SLAB Z Placeholder If P_BSMNT indicates basement \u2192 BASE , otherwise Slab","title":"NSI 2022 FEMA-Enhanced \u2014 Inland Foundation Type Mapping"},{"location":"building_inventories/#nsi-data-schema","text":"{ \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"$id\": \"https://example.com/schemas/nsi_schema.json\", \"title\": \"NSI Buildings Schema\", \"version\": \"0.1.0\", \"description\": \"Schema for NSI (National Structure Inventory) building data\", \"default fields\": { \"target_fid\": { \"type\": \"string\", \"description\": \"Unique identifier for the building\", \"default target field\": \"id\", \"required\": true, \"nullable\": false }, \"occtype\": { \"type\": \"string\", \"description\": \"Occupancy type code (e.g., RES1, COM1)\", \"default target field\": \"occupancy_type\", \"required\": false, \"nullable\": true }, \"found_ht\": { \"type\": \"number\", \"description\": \"First floor height (feet above ground)\", \"default target field\": \"first_floor_height\", \"required\": false, \"nullable\": true }, \"found_type\": { \"type\": \"string\", \"description\": \"Foundation type code (I=Pile, P=Pier, W=Solid Wall, B=Basement, C=Crawl, F=Fill, S=Slab)\", \"default target field\": \"foundation_type\", \"enum\": [\"I\", \"P\", \"W\", \"B\", \"C\", \"F\", \"S\"], \"required\": false, \"nullable\": true }, \"num_story\": { \"type\": \"number\", \"description\": \"Number of stories in the building\", \"default target field\": \"number_stories\", \"required\": true, \"nullable\": false }, \"sqft\": { \"type\": \"number\", \"description\": \"Building area in square feet\", \"default target field\": \"area\", \"required\": true, \"nullable\": false }, \"val_struct\": { \"type\": \"number\", \"description\": \"Building replacement cost ($USD)\", \"default target field\": \"building_cost\", \"required\": true, \"nullable\": false }, \"val_cont\": { \"type\": \"number\", \"description\": \"Contents replacement cost ($USD)\", \"default target field\": \"content_cost\", \"required\": false, \"nullable\": true }, \"bldgtype\": { \"type\": \"string\", \"description\": \"General building type code (e.g., W=Wood, M=Masonry, C=Concrete, S=Steel)\", \"default target field\": \"general_building_type\", \"required\": false, \"nullable\": true } } } However, users may provide a crosswalk (a.k.a. override) from the target fields to the user's non-standard fields. Example of User-Provided Override for NSI Field Names: (keys=target_field, values=user's field) { \"building_cost\": \"my_custom_building_cost_field\" }","title":"NSI Data Schema:"},{"location":"building_inventories/#milliman-market-baskets-data","text":"The Milliman Market Baskets were developed by Milliman, Inc. to support FEMA\u2019s Risk Rating 2.0 initiative . Milliman created Market Baskets for all U.S. states and territories to provide a representative sample of single-family homes (RES1) used in the development of rating factors. Market Basket locations were derived primarily from CoreLogic ParcelPoint data, supplemented with U.S. Census and National Hydrography Dataset (NHD) information, and refined through extensive quality control to ensure accuracy and realistic spatial distribution. Three categories of data, referred to as \u201cbooks\u201d , were created from the Market Baskets: Uniform Book \u2013 Each property assigned identical structural and coverage characteristics, allowing geographic variability to be analyzed independently. Uncorrelated Market Basket \u2013 Contains randomized property and policy characteristics not correlated with geography; foundation type and first-floor height remain linked to prevent implausible combinations. Correlated Market Basket (Inforce Dataset) \u2013 Joined with FEMA policy data (GFE access required); attributes are correlated to reflect realistic joint distributions and align with observed parcel and NFIP exposure data. The Consequences Solution is designed and tested using the Uniform and Uncorrelated Market Basket datasets. Table 6 describes the analysis attributes used across these books. Although the schema is consistent, the method of attribute imputation varies by dataset. For example, the Uncorrelated Market Basket randomizes property and coverage characteristics, while the Correlated Market Basket applies state-specific distributions to more closely represent actual conditions. The Milliman Market Basket datasets support both coastal and inland loss calculations, as they include the necessary structural, coverage, and geographic attributes for each modeling environment. Their use, however, is limited to single-family residential (RES1) structures, as the datasets were specifically developed for rating factor development under FEMA\u2019s NFIP framework. For more details, refer to the FEMA (2022) . Table 6. Milliman Data Attributes for Analysis Analysis Attribute NSI Field Name Data Type Notes X Location LON Double Y Location LAT Double Unique ID Location String Occupancy Type -- -- All points are RES1 Building Value BLDG_VALUE Long Full replacement value Building Insurance Deductible BLDG_DED Long Building Insurance Limit BLDG_LIMIT Long Content Value CNT_VALUE Long Full replacement value Content Insurance Deductible CNT_DED Long Content Insurance Limit CNT_LIMIT Long Number of Stories NUM_STORIES Long Area/Square Footage -- -- Use default area for RES1 based on Hazus Methodolgy, i.e. sqft=1800 General Building Type CONSTR_CODE Long Construction type, ( 1 = W, 2 = M), Use default value W if not provided. Foundation Type foundationtype Long Foundation type, (2 = basement; 4 = crawlspace; 6 = pier; 7 = fill or wall; 8 = slab; 9 = pile) Foundation Height FIRST_FLOOR_ELEV Long First floor height (feet above ground) Basement Type BasementFinishType Long Basement Finish type, (0 = no basement; 1 = unfinished basement; 2 = finished basement) Ground Elevation elev_ft Float Digital Elevation Model (DEM) (ground) elevation (feet NAVD88)","title":"Milliman Market Baskets Data"},{"location":"building_inventories/#milliman-inland-foundation-type-mapping","text":"For both the Uniform Book and Uncorrelated Market Basket datasets, the foundation field contains numeric codes that must be mapped to inland foundation types used by the Consequences Solution. These mappings support correct depth\u2013damage function assignment. Table 7. Milliman Inland Foundation Type Mapping foundation Description Assigned Inland Foundation Type 2 Basement BASE 4 Crawlspace SHAL 6 Pier SHAL 7 Fill / Wall SLAB 8 Slab SLAB 9 Pile PILE","title":"Milliman \u2014 Inland Foundation Type Mapping"},{"location":"building_inventories/#milliman-coastal-foundation-type-mapping","text":"To be developed.","title":"Milliman \u2014 Coastal Foundation Type Mapping"},{"location":"building_inventories/#milliman-data-schema","text":"{ \"$schema\": \"http://json-schema.org/draft-07/schema#\", \"$id\": \"https://example.com/schemas/milliman_schema.json\", \"title\": \"Milliman Buildings Schema\", \"version\": \"0.2.0\", \"description\": \"Typical schema for Milliman building data (Uniform, Uncorrelated Market Basket)\", \"default fields\": { \"accntnum\": { \"type\": \"number\", \"description\": \"unique policy id (0 prefix=market basket, 1 prefix=uncorrelated book, no prefix=uniform book)\", \"default target field\": null, \"required\": false, \"nullable\": true }, \"location\": { \"type\": \"string\", \"description\": \"Location ID of building which serves as the unique identifier\", \"default target field\": \"id\", \"required\": true, \"nullable\": false }, \"BLDG_DED\": { \"type\": \"number\", \"description\": \"Building insurance deductible ($USD)\", \"default target field\": null, \"required\": false, \"nullable\": true }, \"BLDG_LIMIT\": { \"type\": \"number\", \"description\": \"Building insurance limit ($USD)\", \"default target field\": null, \"required\": false, \"nullable\": true }, \"CNT_DED\": { \"type\": \"number\", \"description\": \"Contents insurance deductible ($USD)\", \"default target field\": null, \"required\": false, \"nullable\": true }, \"CNT_LIMIT\": { \"type\": \"number\", \"description\": \"Contents insurance limit ($USD)\", \"default target field\": null, \"required\": false, \"nullable\": true }, \"STATE\": { \"type\": \"string\", \"description\": \"Two-letter state abbreviation\", \"default target field\": null, \"required\": false, \"nullable\": true }, \"POSTCODE\": { \"type\": \"string\", \"description\": \"5-digit ZIP code\", \"default target field\": null, \"required\": false, \"nullable\": true }, \"COUNTRY\": { \"type\": \"string\", \"description\": \"Country code (e.g., US)\", \"default target field\": null, \"required\": false, \"nullable\": true }, \"LON\": { \"type\": \"number\", \"description\": \"Longitude in decimal degrees\", \"default target field\": null, \"required\": true, \"nullable\": false }, \"LAT\": { \"type\": \"number\", \"description\": \"Latitude in decimal degrees\", \"default target field\": null, \"required\": true, \"nullable\": false }, \"BLDG_VALUE\": { \"type\": \"number\", \"description\": \"Building replacement cost ($USD)\", \"default target field\": \"building_cost\", \"required\": true, \"nullable\": false }, \"CNT_VALUE\": { \"type\": \"number\", \"description\": \"Contents replacement cost ($USD)\", \"default target field\": \"content_cost\", \"required\": true, \"nullable\": false }, \"CONSTR_CODE\": { \"type\": \"number\", \"description\": \"Construction type code (1=wood; 2=masonry)\", \"default target field\": \"general_building_type\", \"enum\": [1, 2], \"required\": false, \"nullable\": true }, \"NUM_STORIES\": { \"type\": \"number\", \"description\": \"Number of stories in the building\", \"default target field\": \"number_stories\", \"required\": true, \"nullable\": false }, \"YEAR_BUILT\": { \"type\": \"number\", \"description\": \"Year the building was constructed\", \"default target field\": null, \"required\": false, \"nullable\": true }, \"FoundationType\": { \"type\": \"number\", \"description\": \"Foundation type code (2=basement; 4=crawlspace; 6=pier; 7=fill or wall; 8=slab; 9=pile)\", \"default target field\": \"foundation_type\", \"enum\": [2, 4, 6, 7, 8, 9], \"required\": false, \"nullable\": true }, \"BasementFinishType\": { \"type\": \"number\", \"description\": \"Basement finish type code (0=no basement; 1=unfinished basement; 2=finished basement)\", \"default target field\": null, \"enum\": [0, 1, 2], \"required\": false, \"nullable\": true }, \"FIRST_FLOOR_ELEV\": { \"type\": \"number\", \"description\": \"First floor elevation above ground in\", \"default target field\": \"first_floor_height\", \"required\": true, \"nullable\": false }, \"BASE_FLOOD_ELEV\": { \"type\": \"number\", \"description\": \"Base flood elevation (BFE) in feet\", \"default target field\": null, \"required\": false, \"nullable\": true } } } However, users may provide a crosswalk (a.k.a. override) from the target fields to the user's non-standard fields. Example of User-Provided Override for Milliman Field Names: (keys=target_field, values=user's field) { \"building_cost\": \"my_custom_building_cost_field\" }","title":"Milliman Data Schema:"},{"location":"building_inventories/#user-defined-data","text":"Users can provide custom building inventories for consequence analysis by ensuring their data conforms to the Base Buildings Schema defined above. The Buildings class provides flexible ingestion pathways that support various data formats and field naming conventions.","title":"User Defined Data"},{"location":"building_inventories/#requirements-for-user-defined-inventories","text":"Geometry : Must include valid point geometry (latitude/longitude coordinates) Required Fields : Must contain or allow imputation of: Unique building identifier ( id ) Number of stories ( number_stories ) Building floor area ( area ) Building replacement cost ( building_cost ) Optional Fields : May include (or rely on defaults): Occupancy type, foundation type, first floor height Content cost, inventory cost, construction type Any output fields from previous analyses","title":"Requirements for User-Defined Inventories"},{"location":"building_inventories/#field-mapping-approaches","text":"Approach 1: Use Standard Field Names Create a GeoDataFrame with columns matching target field names or their aliases: import geopandas as gpd import pandas as pd from inland_consequences.buildings import Buildings # Create DataFrame with standard field names data = { 'id': ['B001', 'B002', 'B003'], 'occupancy_type': ['RES1', 'COM1', 'IND2'], 'building_cost': [250000, 500000, 1000000], 'content_cost': [125000, 500000, 1500000], 'number_stories': [2, 1, 3], 'area': [2000, 5000, 10000], 'first_floor_height': [1.0, 2.0, 3.0], 'foundation_type': ['S', 'S', 'B'], 'general_building_type': ['W', 'M', 'C'], 'latitude': [40.7, 40.8, 40.9], 'longitude': [-74.0, -74.1, -74.2] } # Create GeoDataFrame with point geometry gdf = gpd.GeoDataFrame( data, geometry=gpd.points_from_xy(data['longitude'], data['latitude']), crs='EPSG:4326' ) # No overrides needed - fields auto-detected buildings = Buildings(gdf) Approach 2: Provide Field Overrides Map your custom field names to target fields using the overrides parameter: # User has non-standard field names data = { 'building_id': ['B001', 'B002', 'B003'], 'use_code': ['RES1', 'COM1', 'IND2'], 'struct_value': [250000, 500000, 1000000], 'contents_value': [125000, 500000, 1500000], 'floors': [2, 1, 3], 'sqft': [2000, 5000, 10000], 'ffh_ft': [1.0, 2.0, 3.0], 'foundation': ['SLAB', 'SLAB', 'BASEMENT'], 'construction': ['WOOD', 'MASONRY', 'CONCRETE'], 'lat': [40.7, 40.8, 40.9], 'lon': [-74.0, -74.1, -74.2] } gdf = gpd.GeoDataFrame( data, geometry=gpd.points_from_xy(data['lon'], data['lat']), crs='EPSG:4326' ) # Provide explicit mapping from target fields to user's fields overrides = { 'id': 'building_id', 'occupancy_type': 'use_code', 'building_cost': 'struct_value', 'content_cost': 'contents_value', 'number_stories': 'floors', 'area': 'sqft', 'first_floor_height': 'ffh_ft', 'foundation_type': 'foundation', 'general_building_type': 'construction' } buildings = Buildings(gdf, overrides=overrides) Approach 3: Rely on Default Imputation Provide only required fields; optional fields will be imputed using documented defaults: # Minimal dataset - only required fields data = { 'building_id': ['B001', 'B002', 'B003'], 'building_cost': [250000, 500000, 1000000], 'number_stories': [2, 1, 3], 'area': [2000, 5000, 10000], 'latitude': [40.7, 40.8, 40.9], 'longitude': [-74.0, -74.1, -74.2] } gdf = gpd.GeoDataFrame( data, geometry=gpd.points_from_xy(data['longitude'], data['latitude']), crs='EPSG:4326' ) overrides = {'id': 'building_id'} # Optional fields will be imputed: # - occupancy_type: RES1 # - foundation_type: S (Slab) # - first_floor_height: 1.0 ft (slab default) # - general_building_type: W (Wood) # - content_cost: 50% of building_cost (RES1 default) buildings = Buildings(gdf, overrides=overrides)","title":"Field Mapping Approaches"},{"location":"building_inventories/#foundation-type-coding","text":"If your data uses different foundation type codes than the standardized codes (I, P, W, B, C, F, S), you must preprocess your data to translate to the standard codes: Standard Code Description Inland Foundation Type I Pile (Infilled) PILE P Pier/Post SHAL (Shallow) W Solid Wall SHAL (Shallow) B Basement BASE (Basement) C Crawlspace SHAL (Shallow) F Fill SLAB S Slab on Grade SLAB","title":"Foundation Type Coding"},{"location":"building_inventories/#data-validation","text":"The Buildings class performs automatic validation: Required fields present : Verifies all required fields exist (either directly or through aliases) No missing required values : Ensures required fields have no NULL/NaN values Valid geometry : Confirms point geometry is valid and has a coordinate reference system If validation fails, the class raises descriptive errors indicating which fields are missing or invalid.","title":"Data Validation"},{"location":"building_inventories/#example-complete-user-defined-workflow","text":"from inland_consequences.buildings import Buildings from inland_consequences.inland_flood_analysis import InlandFloodAnalysis from inland_consequences.raster_collection import RasterCollection from inland_consequences.default_vulnerability import DefaultVulnerability # 1. Load user's building data user_buildings_gdf = gpd.read_file('my_buildings.gpkg') # 2. Define field mappings field_overrides = { 'id': 'UNIQUE_ID', 'occupancy_type': 'OCCUPANCY', 'building_cost': 'REPLACEMENT_VALUE', 'number_stories': 'NUM_FLOORS', 'area': 'FLOOR_AREA_SQFT' } # 3. Create Buildings object (auto-validates and imputes defaults) buildings = Buildings(user_buildings_gdf, overrides=field_overrides) # 4. Use in analysis hazard_rasters = RasterCollection('flood_depth_*.tif') vulnerability = DefaultVulnerability() with InlandFloodAnalysis(hazard_rasters, buildings, vulnerability) as analysis: analysis.calculate_losses() results_gdf = analysis.buildings.gdf # GeoDataFrame with loss results For additional guidance on default values and imputation strategies, see the Inventory Methodology Documentation .","title":"Example: Complete User-Defined Workflow"},{"location":"buildingvalidation_techapproach/","text":"Building Inventory Validation Flags Technical Approach \u00b6 The building Inventory validation flags are intended to identify structures with attributes that are often, but not always, associated with potential data issues. The validation logic is informed by review of the FFRD Duwamish study results and other recent analyses. The purpose of these flags is to guide user review rather than to automatically invalidate or correct inventory records. All flags are advisory in nature, and the approach is designed to preserve continuity of loss modeling so that results remain available even when a flag is present. Occupancy-Based Area and Valuation Review \u00b6 One component of the validation evaluates building area and valuation consistency relative to the assigned occupancy type. Structures are compared against expected square footage ranges derived from the Hazus hzSqftFactors table. When a structure\u2019s reported area exceeds five times the expected value for its occupancy type, the structure is flagged for review. This condition may indicate an incorrect occupancy assignment, an error in reported building area, or atypical building characteristics. When triggered, the user is notified that the structure has an unusually large area or valuation for the assigned occupancy type and that review of the occupancy type assignment or building area may be warranted. No automated corrections are applied as part of this check. Story Count Consistency by Occupancy Type \u00b6 Another validation assesses consistency between the number of stories assigned to a structure and its occupancy type. Using guidance from the Hazus Inventory Technical Manual, structures are flagged when the reported number of stories is unusual for the assigned occupancy. Certain occupancy types are not typically associated with mid- or high-rise construction, particularly those exceeding three stories, while others are rarely associated with high-rise construction exceeding seven stories. When these thresholds are exceeded, the structure is flagged and the user is advised that the story count is unusual for the assigned occupancy type and should be reviewed. This validation is intended to prompt review of either the story count or the occupancy assignment, recognizing that legitimate exceptions may exist. Special Handling for RES1 Structures \u00b6 Residential single-family structures (RES1) are handled as a special case within the story count validation. RES1 structures with more than three stories are flagged, as this configuration is uncommon within the Hazus framework. To ensure that loss estimates remain available, loss calculations assume a maximum of three stories for RES1 structures while retaining the original story count in the inventory for reporting and review purposes. The user-facing message communicates both the unusual nature of the attribute and the modeling assumption applied for loss estimation. Foundation Type and Flood Zone Consistency \u00b6 Foundation type assignments are also evaluated for consistency with flood zone and location. Structures are flagged when the assigned foundation type is atypical for the mapped flood zone, such as basements located within V-zones. These conditions may indicate misclassification, legacy data artifacts, or localized exceptions and therefore warrant user review. At this stage, no automated changes are applied to foundation attributes; instead, the condition is surfaced through an advisory flag. This validation logic is designed to be extensible, with future enhancements anticipated to address additional scenarios such as post-FIRM basements within the Special Flood Hazard Area. Outputs and Use of Validation Flags \u00b6 Each validation condition produces a discrete flag that is stored as a non-blocking indicator and accompanied by plain-language guidance for the user. Flags are intended to improve transparency and support informed review without interrupting downstream loss modeling workflows unless explicitly noted. Collectively, these validation checks provide a structured and extensible framework for improving inventory quality while maintaining analytical continuity.","title":"Building Inventory Validation Flags Technical Approach"},{"location":"buildingvalidation_techapproach/#building-inventory-validation-flags-technical-approach","text":"The building Inventory validation flags are intended to identify structures with attributes that are often, but not always, associated with potential data issues. The validation logic is informed by review of the FFRD Duwamish study results and other recent analyses. The purpose of these flags is to guide user review rather than to automatically invalidate or correct inventory records. All flags are advisory in nature, and the approach is designed to preserve continuity of loss modeling so that results remain available even when a flag is present.","title":"Building Inventory Validation Flags Technical Approach"},{"location":"buildingvalidation_techapproach/#occupancy-based-area-and-valuation-review","text":"One component of the validation evaluates building area and valuation consistency relative to the assigned occupancy type. Structures are compared against expected square footage ranges derived from the Hazus hzSqftFactors table. When a structure\u2019s reported area exceeds five times the expected value for its occupancy type, the structure is flagged for review. This condition may indicate an incorrect occupancy assignment, an error in reported building area, or atypical building characteristics. When triggered, the user is notified that the structure has an unusually large area or valuation for the assigned occupancy type and that review of the occupancy type assignment or building area may be warranted. No automated corrections are applied as part of this check.","title":"Occupancy-Based Area and Valuation Review"},{"location":"buildingvalidation_techapproach/#story-count-consistency-by-occupancy-type","text":"Another validation assesses consistency between the number of stories assigned to a structure and its occupancy type. Using guidance from the Hazus Inventory Technical Manual, structures are flagged when the reported number of stories is unusual for the assigned occupancy. Certain occupancy types are not typically associated with mid- or high-rise construction, particularly those exceeding three stories, while others are rarely associated with high-rise construction exceeding seven stories. When these thresholds are exceeded, the structure is flagged and the user is advised that the story count is unusual for the assigned occupancy type and should be reviewed. This validation is intended to prompt review of either the story count or the occupancy assignment, recognizing that legitimate exceptions may exist.","title":"Story Count Consistency by Occupancy Type"},{"location":"buildingvalidation_techapproach/#special-handling-for-res1-structures","text":"Residential single-family structures (RES1) are handled as a special case within the story count validation. RES1 structures with more than three stories are flagged, as this configuration is uncommon within the Hazus framework. To ensure that loss estimates remain available, loss calculations assume a maximum of three stories for RES1 structures while retaining the original story count in the inventory for reporting and review purposes. The user-facing message communicates both the unusual nature of the attribute and the modeling assumption applied for loss estimation.","title":"Special Handling for RES1 Structures"},{"location":"buildingvalidation_techapproach/#foundation-type-and-flood-zone-consistency","text":"Foundation type assignments are also evaluated for consistency with flood zone and location. Structures are flagged when the assigned foundation type is atypical for the mapped flood zone, such as basements located within V-zones. These conditions may indicate misclassification, legacy data artifacts, or localized exceptions and therefore warrant user review. At this stage, no automated changes are applied to foundation attributes; instead, the condition is surfaced through an advisory flag. This validation logic is designed to be extensible, with future enhancements anticipated to address additional scenarios such as post-FIRM basements within the Special Flood Hazard Area.","title":"Foundation Type and Flood Zone Consistency"},{"location":"buildingvalidation_techapproach/#outputs-and-use-of-validation-flags","text":"Each validation condition produces a discrete flag that is stored as a non-blocking indicator and accompanied by plain-language guidance for the user. Flags are intended to improve transparency and support informed review without interrupting downstream loss modeling workflows unless explicitly noted. Collectively, these validation checks provide a structured and extensible framework for improving inventory quality while maintaining analytical continuity.","title":"Outputs and Use of Validation Flags"},{"location":"coastal_methodology/","text":"Coastal Consequences Methodology \u00b6 Hazard Data Inputs \u00b6 The coastal consequence methodology relies on a set of core hazard inputs that collectively describe the coastal flooding conditions relevant to damage and loss estimation at each structure. These inputs include water surface levels, wave heights, and associated uncertainty. While designed to ingest probabilistic coastal hazard datasets such as those from the North Atlantic Coast Comprehensive Study (NACCS) and similar probabilistic storm surge/wave products, the methodology is flexible and can operate with any valid hazard data provided in the required formats. The sections below describe the role, requirements, and assumptions associated with each hazard input. Stillwater Elevation Nodal Data (SWEL) \u00b6 Stillwater elevation represents the baseline coastal water level associated with storm surge and tide, excluding direct wave effects. SWEL is a required hazard input and forms the foundation for flood depth and total water level calculations. Hazard datasets are expected as point (nodal) estimates of SWEL at multiple annual-chance exceedance levels (e.g., 1-year through 10,000-year). For each structure, SWEL values are transferred from nearby hazard nodes using a spatial nearest-neighbor averaging approach, which computes a weighted mean of the nearest SWEL values for each frequency. SWEL must be provided in consistent vertical units (feet above a common datum) and aligned with structure elevation data. SWEL Uncertainty Nodal Data \u00b6 SWEL uncertainty quantifies the confidence bounds around the best-estimate water level. Probabilistic coastal hazard products typically include an upper confidence limit (e.g., 84th percentile) in addition to the best estimate. The difference between the upper confidence limit and the best estimate is used to approximate a one-standard-deviation uncertainty for SWEL at each frequency. When uncertainty data are supplied, the methodology propagates this variability into flood depth and total water level uncertainty, which influences damage and loss estimates. If uncertainty is not provided, the model assumes zero uncertainty (deterministic best estimate) for SWEL. Controlling Wave Height (Hc) Nodal Data \u00b6 Wave effects play a critical role in coastal damage processes by contributing to runup, impact forces, and overall structural stress. Controlling wave height (Hc) is the wave metric used in damage estimation and must be supplied for each annual-chance frequency. If input data are provided as significant wave height (Hs), a user must use a conversion factor (e.g., 1.6 \u00d7 Hs) to approximate controlling wave height as a preprocessing step, prior to ingestion into the Consequences Solution. Similar to SWEL, wave height values are spatially transferred to structures using a nearest-neighbor averaging scheme. Controlling wave height inputs is essential for differentiating wave exposure regimes in the damage function assignment. Wave Height Uncertainty (He) Nodal Data \u00b6 Wave height uncertainty quantifies variability in the estimated wave conditions and is typically derived from confidence limit datasets accompanying the best-estimate wave heights. As with SWEL uncertainty, the difference between the upper confidence limit and the best estimate for wave height is used to approximate a one-standard-deviation uncertainty term. This uncertainty is propagated in coastal damage calculations by probabilistically blending depth-damage functions from multiple wave regimes based on the likelihood of different wave height intervals at a given event. For example, if wave height uncertainty indicates a 40% chance of falling within the range of V-Zone damage functions (> 3 feet) and 60% chance of A-Zone (>1 to 3 feet), the DDFs are weighted accordingly. Depth-Damage Function Assignment \u00b6 Structural damage is estimated using coastal-specific depth-damage functions (DDFs) that relate flood depth above the first floor to percent damage. Damage is evaluated over a continuous range of building flood depths (BFDs) from -4 to +16 feet relative to the first-floor elevation (depth in-structure), consistent with the domain of the underlying DDFs. For each building, a family of four depth damage functions are chosen based on the building foundation type, number of stories, and basement finish type. Each of the four damage functions represents a different environmental scenario: DF1: freshwater inundation Although DF1, representing freshwater inundation, is defined for each family of building type, it is not used by this tool to calculate building damage and loss. DF2: saltwater inundation with waves less than 1 feet DF3: saltwater inundation with waves less than or equal to 1 foot and less than 3 feet DF4: saltwater inundation with waves greater than or equal to 3 feet The Coastal Consequences Methodology uses a probabilistic blending approach to combine the three wave-specific damage curves (DF2, DF3, DF4) into a single composite damage curve for each structure. At each building flood depth (BFD), the probability of realizing wave conditions in each wave category is computed using a normal cumulative distribution function (CDF), where the mean is equal to the controlling wave height (Hc) and the standard deviation is equal to the wave height uncertainty (He): Probability of waves < 1 ft = CDF evaluated at 1 ft Probability of waves \u2265 3 ft = 1 \u2212 CDF evaluated at 3 ft Probability of waves \u2265 1 ft and < 3 ft = remainder probability These probabilities are used as weights to combine the three wave-dependent damage curves at each flood depth. The resulting composite damage value is calculated as: \\[ D = \\left(D_{3p} \\cdot P_{3p}\\right) + \\left(D_{1\\text{-}3} \\cdot P_{1\\text{-}3}\\right) + \\left(D_{\\mathrm{lt1}} \\cdot P_{\\mathrm{lt1}}\\right) \\] Where: \\(D\\) = composite percent damage at a given building flood depth \\(D_{3p}\\) = percent damage from the \\(\\ge 3\\) ft wave depth\u2013damage function \\(D_{1\\text{-}3}\\) = percent damage from the 1\u20133 ft wave depth\u2013damage function \\(D_{\\mathrm{lt1}}\\) = percent damage from the \\(<1\\) ft wave depth\u2013damage function \\(P_{3p}\\) = probability of \\(\\ge 3\\) ft wave conditions \\(P_{1\\text{-}3}\\) = probability of 1\u20133 ft wave conditions \\(P_{\\mathrm{lt1}}\\) = probability of \\(<1\\) ft wave conditions This process produces a single, depth-dependent damage curve that reflects both flood depth and uncertainty in wave conditions. Figure 1. Example of a building wave height probabilities (Top) and resultant combined damage function (Bottom). Loss Calculations \u00b6 The coastal consequence methodology calculates building losses by combining hazard inputs, depth-damage functions, and probabilistic event sampling. It translates hazard conditions (stillwater elevation and wave height) into building flood depths, applies the composite DDFs to estimate damage, and integrates across event probabilities to produce annualized loss estimates. The subsections below describe each step. Determining Depth at Structure \u00b6 Determining flood depth at a structure involves transferring coastal hazard information to each building and converting those hazard conditions into depth relative to the building\u2019s first floor. The primary coastal hazard inputs are stillwater elevation (SWEL) and controlling wave height, which are provided at discrete hazard node locations across a range of annual-chance frequencies. To associate these hazard values with individual structures, a nearest-neighbor spatial approach is applied, as illustrated in Figure 2. For each building, the three nearest SWEL nodes are identified, and their values are averaged to assign a mean stillwater elevation at each frequency. An identical process is applied independently to controlling wave height nodes, resulting in a mean wave height value for each structure at each frequency. Uncertainty values for both SWEL and wave height are derived from corresponding confidence-limit datasets and are carried forward for use in damage and loss calculations. Note that user interviews indicated a desire to modify this method by weighting the proximity of the nearest neighbor. Future updates may modify the existing approach where the 3 nearest values all have equal weight. Figure 2. Map of Example Building and Node locations. Determining Depth in Structure (Building Flood Depth) \u00b6 For each structure and annual-chance frequency, the assigned stillwater elevation and wave contribution are combined to derive the Total Water Level (TWL) at the structure. TWL represents the water surface elevation required to produce a given level of inundation and serves as the linkage between coastal hazard inputs and building-level flood depth. The building flood depth (BFD) is then calculated as the difference between the total water level and the structure\u2019s first-floor elevation (FFE). BFD represents the depth of water relative to the first floor (depth in-structure) and is the independent variable used in the application of depth-damage functions. The assigned TWL values across annual-chance frequencies define a building-specific flood frequency curve, which relates water level to annual exceedance probability. For each value of building flood depth, the TWL required to produce that depth is identified using the structure\u2019s first-floor elevation, and the corresponding event probability\u2014or recurrence interval\u2014is extracted from the flood frequency curve. At this stage, the associated hazard attributes, including stillwater elevation, wave height, and their respective uncertainty terms, are transferred to the flood-depth-based calculation table. This process establishes a consistent relationship between flood depth at the structure, the probability of the event producing that depth, and the uncertainty associated with the underlying hazard inputs. Total Water Level Uncertainty \u00b6 Uncertainty in total water level reflects uncertainty in both surge and wave conditions. These uncertainty components are assumed to be independent and are combined using a root-sum-of-squares formulation. The uncertainty associated with total water level (TWLe) is calculated by combining the uncertainty in stillwater elevation (SWELe) and the uncertainty in controlling wave height (He), with a scaling factor applied to account for the conversion from controlling wave height to an equivalent breaking wave contribution consistent with the damage function formulation: \\[ \\mathrm{TWLe} = \\sqrt{(\\mathrm{SWELe})^2 + (0.7 \\cdot \\mathrm{He})^2} \\] The coefficient of 0.7 represents the conversion from controlling wave height to breaking wave height used in coastal damage estimation. Flood Depth Uncertainty at the Structure \u00b6 Flood depth uncertainty represents variability in the estimated depth of inundation relative to the structure\u2019s first floor. This uncertainty arises from two independent sources\u2014uncertainty in total water level and uncertainty in first-floor elevation. Flood depth uncertainty (BFDe) is calculated by combining these components using a root-sum-of-squares approach: \\[ \\mathrm{BFDe} = \\sqrt{(\\mathrm{FFEe})^2 + (\\mathrm{TWLe})^2} \\] where FFEe represents uncertainty in first-floor elevation and TWLe represents uncertainty in total water level. Flood depth uncertainty is propagated into damage calculations by evaluating depth-damage functions at flood depths offset by plus and minus one standard deviation. This approach produces low-, best-, and high-estimate damage and loss values while preserving the nonlinear relationship between flood depth and structural damage. Applying the Depth-Damage Function \u00b6 Once the building flood depth relative to the first floor has been determined for each structure, the depth-damage functions are applied to estimate structural damage. Damage is evaluated using the composite depth-damage function developed for the structure, which integrates building attributes and probabilistic wave effects. For each flood depth, the composite depth-damage function is evaluated to estimate the percent of building damage associated with that level of inundation. To account for uncertainty in flood depth, damage is not evaluated at a single depth alone. Instead, three damage estimates are produced using the same composite damage function evaluated at different depth conditions. The best-estimate damage corresponds to the composite depth-damage function evaluated at the mean building flood depth. The low-estimate damage is obtained by evaluating the damage function at a flood depth reduced by one standard deviation of flood depth uncertainty, while the high-estimate damage is obtained by evaluating the same damage function at a flood depth increased by one standard deviation. This approach propagates flood depth uncertainty through the damage calculation while preserving the nonlinear relationship between depth and structural damage. Figure 3. Example of deriving a low, best- and high-estimate of damage using the combined damage curve and a single value of BFD and associated BFD error. Percent damage values are then converted to monetary losses by multiplying the estimated damage percentage by the structure\u2019s replacement value. Losses are constrained to physically plausible conditions\u2014structures that experience negligible inundation or remain effectively dry under a given event are assigned zero loss. These loss estimates are carried forward for probabilistic sampling and average annualized loss calculations. Generating Probabilistic Events and Storm Elevations \u00b6 To capture the full range of possible events contributing to loss, the methodology uses Monte Carlo sampling to generate a probabilistic set of event probabilities. A user-defined number of random probabilities are sampled between 0.0001 and 1.0. Each probability is mapped to corresponding SWEL and wave values and then to a flood depth and damage estimate. This procedure enables characterization of low-probability, high-impact events that contribute significantly to annualized loss. Alternatively, a suite of predefined storm magnitudes may be used to ensure consistency across analyses. Calculating Average Annualized Loss \u00b6 Average Annualized Loss (AAL) represents the long-term expected annual loss at a structure and is calculated by integrating event losses across the full range of event probabilities. To compute AAL, the low-, best-, and high-estimate losses corresponding to each of the N probabilistic storm events are first paired with their associated event probabilities. These loss\u2013probability pairs are then sorted in descending order of probability to ensure consistent numerical integration across return periods. AAL is calculated by numerically integrating the loss\u2013frequency relationship using a trapezoidal approximation. For each adjacent pair of probabilistic events, the average loss between the two events is weighted by the difference in their return periods. This approach captures the contribution of both frequent, low-loss events and rare, high-loss events to the long-term expected annual loss. The structure-level AAL is calculated as: \\[ \\mathrm{AAL} = \\sum_{i=1}^{n-1} \\left[ (F_i - F_{i+1}) \\cdot \\frac{L_i + L_{i+1}}{2} \\right] + (F_n \\cdot L_n) \\] Where: \\(n = N\\) , the total number of probabilistic events \\(F_i = \\dfrac{1}{\\text{ith Probability}}\\) , the return period associated with event \\(i\\) \\(L_i\\) = loss associated with event \\(i\\) This calculation is performed independently for the low-, best-, and high-estimate loss curves, resulting in three AAL values for each structure\u2014a minimum estimate, a best estimate, and a maximum estimate. These values characterize the expected annual loss while explicitly accounting for uncertainty in hazard intensity, flood depth, and damage response. Results \u00b6 The existing tool provides a range of results output including a results, prep, wave height and water surface shapefile of each building point. In addition, there is a TAB folder containing a .csv for each building analyzed, a run log file and a .tif heat map. Results Shapefile \u00b6 A shapefile of all building points with the fields described below: Field Name Description Data Type FID Sequential numeric ID starts at 0 Object ID Shape Point geometry Geometry BID Sequential numeric ID starts at 1 Long ORIG_ID Original NSI and Milliman ID Text BLDG_DED Building Deductible ($1,500 default) Double BLDG_LIM Building Limit ($200,000 default) Double BLDG_VAL Building Value (USD) Double CNT_DED Content Deductible ($1,000 default) Double CNT_LIM Content Limit ($100,000 default) Double CNT_VALUE Content Value (USD) Double STORY Number of stories Double FOUND Foundation type (2\u20139) Double BASEFIN Basement Finish Flag (0 or 1) Double FFH First floor height (feet) Double DEMFT Ground surface elevation (feet) Double ANLYS Analysis flag (0=no results, 1=included in analysis) Double BAAL Building AAL \"Best Estimate\" (USD) Double BAALmin Building minimum AAL (USD) Double BAALmax Building maximum AAL (USD) Double FLAG_DF16 Damage function flag (0 or 1) Double WSE Shapefile \u00b6 This shapefile contains the water surface elevation and uncertainty value in feet for each return period available at each building point. Fields are also available with the three nearest surge node IDs. A Valid field with a 0 or 1 where 0 is to be excluded from analysis due to having a 95% chance of the DEMFT above the flood elevation of the max event; 1 otherwise. WAV Shapefile \u00b6 This shapefile contains the wave height and uncertainty value in feet for each return period available at each building point. Fields are also available with the three nearest surge node IDs. A Valid field with a 0 or 1 flag is provided that is currently unused. PREP Shapefile \u00b6 This shapefile contains both the WSE and WAV data, as well as four DDFs IDs representing riverine, saltwater, coastal A and V. A DDF ID for erosion is currently unused. A summary of the inventory attributes is also included. Heatmap \u00b6 A .tif grid with a resolution of ~200 meters is created with symbology that provides the total AAL in each grid cell. Run Logfile \u00b6 Processing notes and runtime messages are printed to both the screen and to a text file. A text file that describes the input and output locations, the parallel processing and each major analysis step including validation messages. The text file is named [x]_run.log , and is found in the output directory. Building .csvs \u00b6 A TAB folder contains a .csv for each building analyzed with detailed information if the user chooses. It includes the SWEL and WSE, the DDF probability weighting, the DDF IDs used with the damage percent and losses for the low, best and high hazard values for all return periods. These are provided for all buildings, regardless of exposure to flooding or impacts. Each loss table is a 202 row \u00d7 32 column table (including header row) that will contain the various necessary calculated values to derive building loss at each value of building flood depth from -4 feet to +16 feet by increments of 0.1 feet. The attributes of the table are described below: FIELD Sample VALUE DESC BID 1234 Unique integer building ID generated by code BFD -1.9 Depth of flood above first floor DEM 10.696 Elevation from DEM in feet, NAVD88 FFE 11.696 First Floor Elevation in feet, NAVD88 FFEe 0 Error associated with FFE TWL 9.796 Total Water Elevation in feet, NAVD88 TWLe 1.603 Error associated with TWL BFDe 1.603 Error associated with BFD RP 138.168 Return Period PVAL 0.007237566 Probability (1/RP) SWEL 9.795997218 SWEL in feet, NAVD88 SWELe 1.60332847 Error associated with SWEL WET 0.287238001 Probability that ground at building is flooded Hc 0 Conditional wave height in feet Hce 0 Error associated with Hc PWL1 1 Probability of waves less than 1 foot PW13 0 Probability of waves between 1 and 3 feet PWG3 0 Probability of waves greater than 3 feet DDFfam 2400 Building's Coastal FFRD Depth-damage function family dfx1 0 Damage from DDFx1 (%) dfx2 0.015 Damage from DDFx2 (%) dfx3 0.031 Damage from DDFx3 (%) DAMLw 0 Low Estimate Damage (%) DAMPr 0 BE Combined Damage (%) DAMUp 0.05624 High Estimate Damage (%) BVAL 1008431 Building replacement value ($) rLOSSLw 0 Raw Low Building Loss ($) rLOSSBE 0 Raw BE Building Loss ($) rLOSSUp 56714 Raw High Building Loss ($) Loss_Lw 0 Final Low Building Loss ($) Loss_BE 0 Final BE Building Loss ($) Loss_Up 56714 Final High Building Loss ($) Based on integration with the inland consequences framework, future development is likely to include a notebook interface where the user can highlight and select desired outputs and file types.","title":"Coastal Consequences Methodology"},{"location":"coastal_methodology/#coastal-consequences-methodology","text":"","title":"Coastal Consequences Methodology"},{"location":"coastal_methodology/#hazard-data-inputs","text":"The coastal consequence methodology relies on a set of core hazard inputs that collectively describe the coastal flooding conditions relevant to damage and loss estimation at each structure. These inputs include water surface levels, wave heights, and associated uncertainty. While designed to ingest probabilistic coastal hazard datasets such as those from the North Atlantic Coast Comprehensive Study (NACCS) and similar probabilistic storm surge/wave products, the methodology is flexible and can operate with any valid hazard data provided in the required formats. The sections below describe the role, requirements, and assumptions associated with each hazard input.","title":"Hazard Data Inputs"},{"location":"coastal_methodology/#stillwater-elevation-nodal-data-swel","text":"Stillwater elevation represents the baseline coastal water level associated with storm surge and tide, excluding direct wave effects. SWEL is a required hazard input and forms the foundation for flood depth and total water level calculations. Hazard datasets are expected as point (nodal) estimates of SWEL at multiple annual-chance exceedance levels (e.g., 1-year through 10,000-year). For each structure, SWEL values are transferred from nearby hazard nodes using a spatial nearest-neighbor averaging approach, which computes a weighted mean of the nearest SWEL values for each frequency. SWEL must be provided in consistent vertical units (feet above a common datum) and aligned with structure elevation data.","title":"Stillwater Elevation Nodal Data (SWEL)"},{"location":"coastal_methodology/#swel-uncertainty-nodal-data","text":"SWEL uncertainty quantifies the confidence bounds around the best-estimate water level. Probabilistic coastal hazard products typically include an upper confidence limit (e.g., 84th percentile) in addition to the best estimate. The difference between the upper confidence limit and the best estimate is used to approximate a one-standard-deviation uncertainty for SWEL at each frequency. When uncertainty data are supplied, the methodology propagates this variability into flood depth and total water level uncertainty, which influences damage and loss estimates. If uncertainty is not provided, the model assumes zero uncertainty (deterministic best estimate) for SWEL.","title":"SWEL Uncertainty Nodal Data"},{"location":"coastal_methodology/#controlling-wave-height-hc-nodal-data","text":"Wave effects play a critical role in coastal damage processes by contributing to runup, impact forces, and overall structural stress. Controlling wave height (Hc) is the wave metric used in damage estimation and must be supplied for each annual-chance frequency. If input data are provided as significant wave height (Hs), a user must use a conversion factor (e.g., 1.6 \u00d7 Hs) to approximate controlling wave height as a preprocessing step, prior to ingestion into the Consequences Solution. Similar to SWEL, wave height values are spatially transferred to structures using a nearest-neighbor averaging scheme. Controlling wave height inputs is essential for differentiating wave exposure regimes in the damage function assignment.","title":"Controlling Wave Height (Hc) Nodal Data"},{"location":"coastal_methodology/#wave-height-uncertainty-he-nodal-data","text":"Wave height uncertainty quantifies variability in the estimated wave conditions and is typically derived from confidence limit datasets accompanying the best-estimate wave heights. As with SWEL uncertainty, the difference between the upper confidence limit and the best estimate for wave height is used to approximate a one-standard-deviation uncertainty term. This uncertainty is propagated in coastal damage calculations by probabilistically blending depth-damage functions from multiple wave regimes based on the likelihood of different wave height intervals at a given event. For example, if wave height uncertainty indicates a 40% chance of falling within the range of V-Zone damage functions (> 3 feet) and 60% chance of A-Zone (>1 to 3 feet), the DDFs are weighted accordingly.","title":"Wave Height Uncertainty (He) Nodal Data"},{"location":"coastal_methodology/#depth-damage-function-assignment","text":"Structural damage is estimated using coastal-specific depth-damage functions (DDFs) that relate flood depth above the first floor to percent damage. Damage is evaluated over a continuous range of building flood depths (BFDs) from -4 to +16 feet relative to the first-floor elevation (depth in-structure), consistent with the domain of the underlying DDFs. For each building, a family of four depth damage functions are chosen based on the building foundation type, number of stories, and basement finish type. Each of the four damage functions represents a different environmental scenario: DF1: freshwater inundation Although DF1, representing freshwater inundation, is defined for each family of building type, it is not used by this tool to calculate building damage and loss. DF2: saltwater inundation with waves less than 1 feet DF3: saltwater inundation with waves less than or equal to 1 foot and less than 3 feet DF4: saltwater inundation with waves greater than or equal to 3 feet The Coastal Consequences Methodology uses a probabilistic blending approach to combine the three wave-specific damage curves (DF2, DF3, DF4) into a single composite damage curve for each structure. At each building flood depth (BFD), the probability of realizing wave conditions in each wave category is computed using a normal cumulative distribution function (CDF), where the mean is equal to the controlling wave height (Hc) and the standard deviation is equal to the wave height uncertainty (He): Probability of waves < 1 ft = CDF evaluated at 1 ft Probability of waves \u2265 3 ft = 1 \u2212 CDF evaluated at 3 ft Probability of waves \u2265 1 ft and < 3 ft = remainder probability These probabilities are used as weights to combine the three wave-dependent damage curves at each flood depth. The resulting composite damage value is calculated as: \\[ D = \\left(D_{3p} \\cdot P_{3p}\\right) + \\left(D_{1\\text{-}3} \\cdot P_{1\\text{-}3}\\right) + \\left(D_{\\mathrm{lt1}} \\cdot P_{\\mathrm{lt1}}\\right) \\] Where: \\(D\\) = composite percent damage at a given building flood depth \\(D_{3p}\\) = percent damage from the \\(\\ge 3\\) ft wave depth\u2013damage function \\(D_{1\\text{-}3}\\) = percent damage from the 1\u20133 ft wave depth\u2013damage function \\(D_{\\mathrm{lt1}}\\) = percent damage from the \\(<1\\) ft wave depth\u2013damage function \\(P_{3p}\\) = probability of \\(\\ge 3\\) ft wave conditions \\(P_{1\\text{-}3}\\) = probability of 1\u20133 ft wave conditions \\(P_{\\mathrm{lt1}}\\) = probability of \\(<1\\) ft wave conditions This process produces a single, depth-dependent damage curve that reflects both flood depth and uncertainty in wave conditions. Figure 1. Example of a building wave height probabilities (Top) and resultant combined damage function (Bottom).","title":"Depth-Damage Function Assignment"},{"location":"coastal_methodology/#loss-calculations","text":"The coastal consequence methodology calculates building losses by combining hazard inputs, depth-damage functions, and probabilistic event sampling. It translates hazard conditions (stillwater elevation and wave height) into building flood depths, applies the composite DDFs to estimate damage, and integrates across event probabilities to produce annualized loss estimates. The subsections below describe each step.","title":"Loss Calculations"},{"location":"coastal_methodology/#determining-depth-at-structure","text":"Determining flood depth at a structure involves transferring coastal hazard information to each building and converting those hazard conditions into depth relative to the building\u2019s first floor. The primary coastal hazard inputs are stillwater elevation (SWEL) and controlling wave height, which are provided at discrete hazard node locations across a range of annual-chance frequencies. To associate these hazard values with individual structures, a nearest-neighbor spatial approach is applied, as illustrated in Figure 2. For each building, the three nearest SWEL nodes are identified, and their values are averaged to assign a mean stillwater elevation at each frequency. An identical process is applied independently to controlling wave height nodes, resulting in a mean wave height value for each structure at each frequency. Uncertainty values for both SWEL and wave height are derived from corresponding confidence-limit datasets and are carried forward for use in damage and loss calculations. Note that user interviews indicated a desire to modify this method by weighting the proximity of the nearest neighbor. Future updates may modify the existing approach where the 3 nearest values all have equal weight. Figure 2. Map of Example Building and Node locations.","title":"Determining Depth at Structure"},{"location":"coastal_methodology/#determining-depth-in-structure-building-flood-depth","text":"For each structure and annual-chance frequency, the assigned stillwater elevation and wave contribution are combined to derive the Total Water Level (TWL) at the structure. TWL represents the water surface elevation required to produce a given level of inundation and serves as the linkage between coastal hazard inputs and building-level flood depth. The building flood depth (BFD) is then calculated as the difference between the total water level and the structure\u2019s first-floor elevation (FFE). BFD represents the depth of water relative to the first floor (depth in-structure) and is the independent variable used in the application of depth-damage functions. The assigned TWL values across annual-chance frequencies define a building-specific flood frequency curve, which relates water level to annual exceedance probability. For each value of building flood depth, the TWL required to produce that depth is identified using the structure\u2019s first-floor elevation, and the corresponding event probability\u2014or recurrence interval\u2014is extracted from the flood frequency curve. At this stage, the associated hazard attributes, including stillwater elevation, wave height, and their respective uncertainty terms, are transferred to the flood-depth-based calculation table. This process establishes a consistent relationship between flood depth at the structure, the probability of the event producing that depth, and the uncertainty associated with the underlying hazard inputs.","title":"Determining Depth in Structure (Building Flood Depth)"},{"location":"coastal_methodology/#total-water-level-uncertainty","text":"Uncertainty in total water level reflects uncertainty in both surge and wave conditions. These uncertainty components are assumed to be independent and are combined using a root-sum-of-squares formulation. The uncertainty associated with total water level (TWLe) is calculated by combining the uncertainty in stillwater elevation (SWELe) and the uncertainty in controlling wave height (He), with a scaling factor applied to account for the conversion from controlling wave height to an equivalent breaking wave contribution consistent with the damage function formulation: \\[ \\mathrm{TWLe} = \\sqrt{(\\mathrm{SWELe})^2 + (0.7 \\cdot \\mathrm{He})^2} \\] The coefficient of 0.7 represents the conversion from controlling wave height to breaking wave height used in coastal damage estimation.","title":"Total Water Level Uncertainty"},{"location":"coastal_methodology/#flood-depth-uncertainty-at-the-structure","text":"Flood depth uncertainty represents variability in the estimated depth of inundation relative to the structure\u2019s first floor. This uncertainty arises from two independent sources\u2014uncertainty in total water level and uncertainty in first-floor elevation. Flood depth uncertainty (BFDe) is calculated by combining these components using a root-sum-of-squares approach: \\[ \\mathrm{BFDe} = \\sqrt{(\\mathrm{FFEe})^2 + (\\mathrm{TWLe})^2} \\] where FFEe represents uncertainty in first-floor elevation and TWLe represents uncertainty in total water level. Flood depth uncertainty is propagated into damage calculations by evaluating depth-damage functions at flood depths offset by plus and minus one standard deviation. This approach produces low-, best-, and high-estimate damage and loss values while preserving the nonlinear relationship between flood depth and structural damage.","title":"Flood Depth Uncertainty at the Structure"},{"location":"coastal_methodology/#applying-the-depth-damage-function","text":"Once the building flood depth relative to the first floor has been determined for each structure, the depth-damage functions are applied to estimate structural damage. Damage is evaluated using the composite depth-damage function developed for the structure, which integrates building attributes and probabilistic wave effects. For each flood depth, the composite depth-damage function is evaluated to estimate the percent of building damage associated with that level of inundation. To account for uncertainty in flood depth, damage is not evaluated at a single depth alone. Instead, three damage estimates are produced using the same composite damage function evaluated at different depth conditions. The best-estimate damage corresponds to the composite depth-damage function evaluated at the mean building flood depth. The low-estimate damage is obtained by evaluating the damage function at a flood depth reduced by one standard deviation of flood depth uncertainty, while the high-estimate damage is obtained by evaluating the same damage function at a flood depth increased by one standard deviation. This approach propagates flood depth uncertainty through the damage calculation while preserving the nonlinear relationship between depth and structural damage. Figure 3. Example of deriving a low, best- and high-estimate of damage using the combined damage curve and a single value of BFD and associated BFD error. Percent damage values are then converted to monetary losses by multiplying the estimated damage percentage by the structure\u2019s replacement value. Losses are constrained to physically plausible conditions\u2014structures that experience negligible inundation or remain effectively dry under a given event are assigned zero loss. These loss estimates are carried forward for probabilistic sampling and average annualized loss calculations.","title":"Applying the Depth-Damage Function"},{"location":"coastal_methodology/#generating-probabilistic-events-and-storm-elevations","text":"To capture the full range of possible events contributing to loss, the methodology uses Monte Carlo sampling to generate a probabilistic set of event probabilities. A user-defined number of random probabilities are sampled between 0.0001 and 1.0. Each probability is mapped to corresponding SWEL and wave values and then to a flood depth and damage estimate. This procedure enables characterization of low-probability, high-impact events that contribute significantly to annualized loss. Alternatively, a suite of predefined storm magnitudes may be used to ensure consistency across analyses.","title":"Generating Probabilistic Events and Storm Elevations"},{"location":"coastal_methodology/#calculating-average-annualized-loss","text":"Average Annualized Loss (AAL) represents the long-term expected annual loss at a structure and is calculated by integrating event losses across the full range of event probabilities. To compute AAL, the low-, best-, and high-estimate losses corresponding to each of the N probabilistic storm events are first paired with their associated event probabilities. These loss\u2013probability pairs are then sorted in descending order of probability to ensure consistent numerical integration across return periods. AAL is calculated by numerically integrating the loss\u2013frequency relationship using a trapezoidal approximation. For each adjacent pair of probabilistic events, the average loss between the two events is weighted by the difference in their return periods. This approach captures the contribution of both frequent, low-loss events and rare, high-loss events to the long-term expected annual loss. The structure-level AAL is calculated as: \\[ \\mathrm{AAL} = \\sum_{i=1}^{n-1} \\left[ (F_i - F_{i+1}) \\cdot \\frac{L_i + L_{i+1}}{2} \\right] + (F_n \\cdot L_n) \\] Where: \\(n = N\\) , the total number of probabilistic events \\(F_i = \\dfrac{1}{\\text{ith Probability}}\\) , the return period associated with event \\(i\\) \\(L_i\\) = loss associated with event \\(i\\) This calculation is performed independently for the low-, best-, and high-estimate loss curves, resulting in three AAL values for each structure\u2014a minimum estimate, a best estimate, and a maximum estimate. These values characterize the expected annual loss while explicitly accounting for uncertainty in hazard intensity, flood depth, and damage response.","title":"Calculating Average Annualized Loss"},{"location":"coastal_methodology/#results","text":"The existing tool provides a range of results output including a results, prep, wave height and water surface shapefile of each building point. In addition, there is a TAB folder containing a .csv for each building analyzed, a run log file and a .tif heat map.","title":"Results"},{"location":"coastal_methodology/#results-shapefile","text":"A shapefile of all building points with the fields described below: Field Name Description Data Type FID Sequential numeric ID starts at 0 Object ID Shape Point geometry Geometry BID Sequential numeric ID starts at 1 Long ORIG_ID Original NSI and Milliman ID Text BLDG_DED Building Deductible ($1,500 default) Double BLDG_LIM Building Limit ($200,000 default) Double BLDG_VAL Building Value (USD) Double CNT_DED Content Deductible ($1,000 default) Double CNT_LIM Content Limit ($100,000 default) Double CNT_VALUE Content Value (USD) Double STORY Number of stories Double FOUND Foundation type (2\u20139) Double BASEFIN Basement Finish Flag (0 or 1) Double FFH First floor height (feet) Double DEMFT Ground surface elevation (feet) Double ANLYS Analysis flag (0=no results, 1=included in analysis) Double BAAL Building AAL \"Best Estimate\" (USD) Double BAALmin Building minimum AAL (USD) Double BAALmax Building maximum AAL (USD) Double FLAG_DF16 Damage function flag (0 or 1) Double","title":"Results Shapefile"},{"location":"coastal_methodology/#wse-shapefile","text":"This shapefile contains the water surface elevation and uncertainty value in feet for each return period available at each building point. Fields are also available with the three nearest surge node IDs. A Valid field with a 0 or 1 where 0 is to be excluded from analysis due to having a 95% chance of the DEMFT above the flood elevation of the max event; 1 otherwise.","title":"WSE Shapefile"},{"location":"coastal_methodology/#wav-shapefile","text":"This shapefile contains the wave height and uncertainty value in feet for each return period available at each building point. Fields are also available with the three nearest surge node IDs. A Valid field with a 0 or 1 flag is provided that is currently unused.","title":"WAV Shapefile"},{"location":"coastal_methodology/#prep-shapefile","text":"This shapefile contains both the WSE and WAV data, as well as four DDFs IDs representing riverine, saltwater, coastal A and V. A DDF ID for erosion is currently unused. A summary of the inventory attributes is also included.","title":"PREP Shapefile"},{"location":"coastal_methodology/#heatmap","text":"A .tif grid with a resolution of ~200 meters is created with symbology that provides the total AAL in each grid cell.","title":"Heatmap"},{"location":"coastal_methodology/#run-logfile","text":"Processing notes and runtime messages are printed to both the screen and to a text file. A text file that describes the input and output locations, the parallel processing and each major analysis step including validation messages. The text file is named [x]_run.log , and is found in the output directory.","title":"Run Logfile"},{"location":"coastal_methodology/#building-csvs","text":"A TAB folder contains a .csv for each building analyzed with detailed information if the user chooses. It includes the SWEL and WSE, the DDF probability weighting, the DDF IDs used with the damage percent and losses for the low, best and high hazard values for all return periods. These are provided for all buildings, regardless of exposure to flooding or impacts. Each loss table is a 202 row \u00d7 32 column table (including header row) that will contain the various necessary calculated values to derive building loss at each value of building flood depth from -4 feet to +16 feet by increments of 0.1 feet. The attributes of the table are described below: FIELD Sample VALUE DESC BID 1234 Unique integer building ID generated by code BFD -1.9 Depth of flood above first floor DEM 10.696 Elevation from DEM in feet, NAVD88 FFE 11.696 First Floor Elevation in feet, NAVD88 FFEe 0 Error associated with FFE TWL 9.796 Total Water Elevation in feet, NAVD88 TWLe 1.603 Error associated with TWL BFDe 1.603 Error associated with BFD RP 138.168 Return Period PVAL 0.007237566 Probability (1/RP) SWEL 9.795997218 SWEL in feet, NAVD88 SWELe 1.60332847 Error associated with SWEL WET 0.287238001 Probability that ground at building is flooded Hc 0 Conditional wave height in feet Hce 0 Error associated with Hc PWL1 1 Probability of waves less than 1 foot PW13 0 Probability of waves between 1 and 3 feet PWG3 0 Probability of waves greater than 3 feet DDFfam 2400 Building's Coastal FFRD Depth-damage function family dfx1 0 Damage from DDFx1 (%) dfx2 0.015 Damage from DDFx2 (%) dfx3 0.031 Damage from DDFx3 (%) DAMLw 0 Low Estimate Damage (%) DAMPr 0 BE Combined Damage (%) DAMUp 0.05624 High Estimate Damage (%) BVAL 1008431 Building replacement value ($) rLOSSLw 0 Raw Low Building Loss ($) rLOSSBE 0 Raw BE Building Loss ($) rLOSSUp 56714 Raw High Building Loss ($) Loss_Lw 0 Final Low Building Loss ($) Loss_BE 0 Final BE Building Loss ($) Loss_Up 56714 Final High Building Loss ($) Based on integration with the inland consequences framework, future development is likely to include a notebook interface where the user can highlight and select desired outputs and file types.","title":"Building .csvs"},{"location":"ddf_tech_implementation/","text":"Inland Consequences Depth-Damage Function Technical Implementation \u00b6 This outlines the technical implementation of the depth-damage function for the inland consequences aspects of the Consequences Solution. This approach may be expanded to coastal depth-damage functions in a future enhancement. Vectorized Depth-Damage Function (DDF) Matching \u00b6 This component is responsible for assigning a single Depth-Damage Function (DDF) to each building by comparing the building\u2019s characteristics to a pre-generated lookup table of damage-function rules. The goal is to make the assignment process fast, consistent, and transparent while supporting large building inventories. Rather than processing buildings one at a time, the implementation uses a vectorized approach, meaning that all buildings are evaluated simultaneously using table joins and grouped logic. This avoids slow per-building loops and ensures that the same rules are applied uniformly across the dataset. The function takes two inputs: a buildings table and a flattened lookup table. The buildings table contains one row per structure and includes attributes that influence flood damage, such as construction type, occupancy, foundation type, number of stories, square footage, and flood peril type. The lookup table contains the rules that map combinations of those attributes to specific damage-function identifiers, along with valid ranges for stories and square footage. Table 1. Building Table Required Fields Column_Name Description Notes S_GENERALBUILDINGTYPE Construction / material class Examples: W (wood), C (concrete), S (steel) S_OCCTYPE Occupancy type Examples: RES1, COM1 S_NUMSTORY Number of stories Used for story range matching S_SQFT Building square footage Optional; defaults to 0 if missing Foundation_Type Foundation type Examples: SLAB, BASE, CRAWL Flood_Peril_Type Flood peril classification Used to distinguish flood types (e.g., riverine vs coastal) Before matching begins, the building attributes are normalized. Text fields are converted to uppercase and trimmed to avoid mismatches caused by formatting differences, and numeric fields such as story count and square footage are converted to numbers. This normalization step ensures that equivalent values are treated consistently during matching. Table 2. Depth-Damage Function Lookup Table Fields Column_Name Description Notes Construction_Type Construction type or general building type Must match building construction type Occupancy_Type Occupancy type Must match building occupancy Foundation_Type Foundation type Must match building foundation Flood_Peril_Type Flood peril classification Must match building flood peril Story_Min Minimum supported story count Inclusive Story_Max Maximum supported story count Inclusive SQFT_Min Minimum supported square footage Blank or null means no lower bound SQFT_Max Maximum supported square footage Blank or null means no upper bound FLSBT_Range Descriptive story range label Used for diagnostics and reporting Damage_Function_ID Depth-damage function identifier Used to retrieve the DDF curve The matching process begins by identifying candidate lookup rows for each building. This is done by requiring an exact match on a small set of core attributes: construction type, occupancy type, foundation type, and flood peril type. These attributes define the basic damage context for a building and act as the primary filter. If no lookup rows match on these core attributes, the building is marked as having no applicable damage function. If one or more candidate rows exist, the process continues to more detailed checks on the number of stories. The function evaluates whether the building\u2019s number of stories falls within the valid range specified by each lookup row. A building must have a story count that lies between the lookup row\u2019s minimum and maximum values to remain a valid match. If none of the candidates meet this condition, the building is flagged as being outside the supported story range. For candidates that pass the story check, the function then evaluates square footage constraints. Some lookup rows specify minimum or maximum square-footage limits, while others do not. When no limits are provided, the range is treated as unbounded. If square-footage limits are present, the building\u2019s size must fall within those bounds. Buildings that pass the story check but fail all square-footage checks are flagged accordingly. Table 3. Match Status Decriptions Match_Status Meaning What it indicates No_Match No lookup row matched the required key attributes The building\u2019s construction, occupancy, foundation, or flood peril type is not represented in the lookup table Story_Out_Of_Range Lookup candidates existed, but none covered the building\u2019s story count The building type is recognized, but its number of stories falls outside all supported story ranges SQFT_Out_Of_Range Lookup candidates matched the building type and story range, but not square footage The building size falls outside the square-footage limits defined in the lookup rules Matched At least one lookup row passed all matching checks A valid depth-damage function was assigned to the building For candidates, that exceed the range for the number of stories or square-footage, they are assigned the highest allowed values for their attribute combination. The selected lookup row provides the building\u2019s assigned Damage Function ID, which corresponds to a secondary lookup table containing the percentage damage at each stage depth. The function returns the original buildings table with additional columns appended. These columns include the selected damage-function identifier, the matched story range, and the match status. Buildings that could not be matched retain null values for the damage-function fields, along with a status that explains why no assignment was made.","title":"Inland Consequences Depth-Damage Function Technical Implementation"},{"location":"ddf_tech_implementation/#inland-consequences-depth-damage-function-technical-implementation","text":"This outlines the technical implementation of the depth-damage function for the inland consequences aspects of the Consequences Solution. This approach may be expanded to coastal depth-damage functions in a future enhancement.","title":"Inland Consequences Depth-Damage Function Technical Implementation"},{"location":"ddf_tech_implementation/#vectorized-depth-damage-function-ddf-matching","text":"This component is responsible for assigning a single Depth-Damage Function (DDF) to each building by comparing the building\u2019s characteristics to a pre-generated lookup table of damage-function rules. The goal is to make the assignment process fast, consistent, and transparent while supporting large building inventories. Rather than processing buildings one at a time, the implementation uses a vectorized approach, meaning that all buildings are evaluated simultaneously using table joins and grouped logic. This avoids slow per-building loops and ensures that the same rules are applied uniformly across the dataset. The function takes two inputs: a buildings table and a flattened lookup table. The buildings table contains one row per structure and includes attributes that influence flood damage, such as construction type, occupancy, foundation type, number of stories, square footage, and flood peril type. The lookup table contains the rules that map combinations of those attributes to specific damage-function identifiers, along with valid ranges for stories and square footage. Table 1. Building Table Required Fields Column_Name Description Notes S_GENERALBUILDINGTYPE Construction / material class Examples: W (wood), C (concrete), S (steel) S_OCCTYPE Occupancy type Examples: RES1, COM1 S_NUMSTORY Number of stories Used for story range matching S_SQFT Building square footage Optional; defaults to 0 if missing Foundation_Type Foundation type Examples: SLAB, BASE, CRAWL Flood_Peril_Type Flood peril classification Used to distinguish flood types (e.g., riverine vs coastal) Before matching begins, the building attributes are normalized. Text fields are converted to uppercase and trimmed to avoid mismatches caused by formatting differences, and numeric fields such as story count and square footage are converted to numbers. This normalization step ensures that equivalent values are treated consistently during matching. Table 2. Depth-Damage Function Lookup Table Fields Column_Name Description Notes Construction_Type Construction type or general building type Must match building construction type Occupancy_Type Occupancy type Must match building occupancy Foundation_Type Foundation type Must match building foundation Flood_Peril_Type Flood peril classification Must match building flood peril Story_Min Minimum supported story count Inclusive Story_Max Maximum supported story count Inclusive SQFT_Min Minimum supported square footage Blank or null means no lower bound SQFT_Max Maximum supported square footage Blank or null means no upper bound FLSBT_Range Descriptive story range label Used for diagnostics and reporting Damage_Function_ID Depth-damage function identifier Used to retrieve the DDF curve The matching process begins by identifying candidate lookup rows for each building. This is done by requiring an exact match on a small set of core attributes: construction type, occupancy type, foundation type, and flood peril type. These attributes define the basic damage context for a building and act as the primary filter. If no lookup rows match on these core attributes, the building is marked as having no applicable damage function. If one or more candidate rows exist, the process continues to more detailed checks on the number of stories. The function evaluates whether the building\u2019s number of stories falls within the valid range specified by each lookup row. A building must have a story count that lies between the lookup row\u2019s minimum and maximum values to remain a valid match. If none of the candidates meet this condition, the building is flagged as being outside the supported story range. For candidates that pass the story check, the function then evaluates square footage constraints. Some lookup rows specify minimum or maximum square-footage limits, while others do not. When no limits are provided, the range is treated as unbounded. If square-footage limits are present, the building\u2019s size must fall within those bounds. Buildings that pass the story check but fail all square-footage checks are flagged accordingly. Table 3. Match Status Decriptions Match_Status Meaning What it indicates No_Match No lookup row matched the required key attributes The building\u2019s construction, occupancy, foundation, or flood peril type is not represented in the lookup table Story_Out_Of_Range Lookup candidates existed, but none covered the building\u2019s story count The building type is recognized, but its number of stories falls outside all supported story ranges SQFT_Out_Of_Range Lookup candidates matched the building type and story range, but not square footage The building size falls outside the square-footage limits defined in the lookup rules Matched At least one lookup row passed all matching checks A valid depth-damage function was assigned to the building For candidates, that exceed the range for the number of stories or square-footage, they are assigned the highest allowed values for their attribute combination. The selected lookup row provides the building\u2019s assigned Damage Function ID, which corresponds to a secondary lookup table containing the percentage damage at each stage depth. The function returns the original buildings table with additional columns appended. These columns include the selected damage-function identifier, the matched story range, and the match status. Buildings that could not be matched retain null values for the damage-function fields, along with a status that explains why no assignment was made.","title":"Vectorized Depth-Damage Function (DDF) Matching"},{"location":"hazardvalidation_techapproach/","text":"Hazard Validation Flag Technical Approach \u00b6 This approach defines a set of hazard-based validation flags intended to identify unusual or inconsistent hazard and loss characteristics at the structure level that may indicate potential issues with building location, hazard inputs, or damage function assignment. These conditions are often, but not always, associated with data anomalies and are intended to prompt user review rather than trigger automatic correction or exclusion. All flags are advisory in nature and are designed to support improved interpretability and confidence in hazard and loss outputs while maintaining continuity of downstream analyses. Structure-Level Depth and Velocity Anomalies \u00b6 One component of the hazard validation focuses on identifying unusually high flood depths and velocities at or within structures for a given return period. For the 10-year return period, structures are flagged when flood depths in-structure exceed five feet or velocities exceed ten feet per second, as these conditions are uncommon for frequent events and may indicate erroneous building locations, spatial misalignment, or localized issues within the hazard data. For all other return periods, more conservative thresholds are applied, with structures flagged when depths exceed twenty feet in-structure or velocities exceed thirty feet per second. While these thresholds may be refined by return period in the future, they are intended to capture the majority of anomalous conditions without over-flagging typical high-hazard environments. When triggered, the user is notified that hazard parameters are unusually high and should be reviewed for potential location or hazard data anomalies. From a combined hazard and loss perspective, unusually high depths or velocities occurring at or within structures, particularly for frequent return periods, are treated as strong indicators of potential issues with the underlying hazard data or structure placement. These conditions are surfaced through advisory flags to support targeted review. Loss Ratio Consistency Checks \u00b6 Additional validation evaluates the consistency of modeled losses relative to exposed value. Structures are flagged when building or content loss ratios exceed 1.0, indicating modeled losses greater than 100 percent of the associated value. These conditions typically suggest issues with depth-damage function assignment, value attribution, or hazard inputs and warrant further review. No automatic adjustments are applied as part of this validation. For frequent events, additional scrutiny is applied to loss severity. Structures with 10-year return period losses exceeding 50 percent of building or content value are flagged for review, as such high losses during frequent events often indicate erroneous building locations or anomalies in the hazard data. These flags are intended to draw attention to potentially unrealistic hazard\u2013exposure interactions. Average Annual Loss Ratio Review \u00b6 Average Annual Loss (AAL) ratios are also evaluated as part of the hazard validation framework. Structures with AAL loss ratios exceeding 10 percent are flagged for review, as unusually high AAL values may indicate persistent exposure to extreme hazard conditions, mislocated structures, or inconsistencies across return period hazard inputs. This validation supports identification of cases where aggregated loss behavior is inconsistent with expected hazard frequency and severity. Return Period Monotonicity and Uncertainty Consistency \u00b6 The final hazard validation evaluates consistency of flood depths and velocities across return periods. Flood depths and velocities at a structure are expected to increase monotonically with increasing return period, following the sequence 10-, 20-, 50-, 100-, 200-, 500-, 1,000-, and 2,000-year events. Structures are flagged when this monotonic relationship is violated, as such patterns may indicate issues with hazard surface generation, interpolation artifacts, or uncertainty handling. This validation extends to cases where uncertainty is applied. Minimum and maximum hazard values derived from uncertainty bounds are expected to preserve the same increasing relationship across return periods. For example, the minimum flood depth for the 2,000-year event, even when computed as mean minus standard deviation, should exceed the corresponding minimum for the 1,000-year event. Violations of this expectation are flagged for review to ensure internal consistency of probabilistic hazard inputs. Outputs and Use of Hazard Validation Flags \u00b6 Each hazard validation condition produces a discrete, non-blocking flag accompanied by plain-language guidance indicating the nature of the anomaly and the recommended focus of review. Flags are advisory and are intended to support transparency, diagnostics, and informed quality assurance without interrupting loss modeling workflows. Collectively, these validations provide a structured framework for identifying potential hazard and loss inconsistencies while preserving analytical continuity.","title":"Hazard Validation Flag Technical Approach"},{"location":"hazardvalidation_techapproach/#hazard-validation-flag-technical-approach","text":"This approach defines a set of hazard-based validation flags intended to identify unusual or inconsistent hazard and loss characteristics at the structure level that may indicate potential issues with building location, hazard inputs, or damage function assignment. These conditions are often, but not always, associated with data anomalies and are intended to prompt user review rather than trigger automatic correction or exclusion. All flags are advisory in nature and are designed to support improved interpretability and confidence in hazard and loss outputs while maintaining continuity of downstream analyses.","title":"Hazard Validation Flag Technical Approach"},{"location":"hazardvalidation_techapproach/#structure-level-depth-and-velocity-anomalies","text":"One component of the hazard validation focuses on identifying unusually high flood depths and velocities at or within structures for a given return period. For the 10-year return period, structures are flagged when flood depths in-structure exceed five feet or velocities exceed ten feet per second, as these conditions are uncommon for frequent events and may indicate erroneous building locations, spatial misalignment, or localized issues within the hazard data. For all other return periods, more conservative thresholds are applied, with structures flagged when depths exceed twenty feet in-structure or velocities exceed thirty feet per second. While these thresholds may be refined by return period in the future, they are intended to capture the majority of anomalous conditions without over-flagging typical high-hazard environments. When triggered, the user is notified that hazard parameters are unusually high and should be reviewed for potential location or hazard data anomalies. From a combined hazard and loss perspective, unusually high depths or velocities occurring at or within structures, particularly for frequent return periods, are treated as strong indicators of potential issues with the underlying hazard data or structure placement. These conditions are surfaced through advisory flags to support targeted review.","title":"Structure-Level Depth and Velocity Anomalies"},{"location":"hazardvalidation_techapproach/#loss-ratio-consistency-checks","text":"Additional validation evaluates the consistency of modeled losses relative to exposed value. Structures are flagged when building or content loss ratios exceed 1.0, indicating modeled losses greater than 100 percent of the associated value. These conditions typically suggest issues with depth-damage function assignment, value attribution, or hazard inputs and warrant further review. No automatic adjustments are applied as part of this validation. For frequent events, additional scrutiny is applied to loss severity. Structures with 10-year return period losses exceeding 50 percent of building or content value are flagged for review, as such high losses during frequent events often indicate erroneous building locations or anomalies in the hazard data. These flags are intended to draw attention to potentially unrealistic hazard\u2013exposure interactions.","title":"Loss Ratio Consistency Checks"},{"location":"hazardvalidation_techapproach/#average-annual-loss-ratio-review","text":"Average Annual Loss (AAL) ratios are also evaluated as part of the hazard validation framework. Structures with AAL loss ratios exceeding 10 percent are flagged for review, as unusually high AAL values may indicate persistent exposure to extreme hazard conditions, mislocated structures, or inconsistencies across return period hazard inputs. This validation supports identification of cases where aggregated loss behavior is inconsistent with expected hazard frequency and severity.","title":"Average Annual Loss Ratio Review"},{"location":"hazardvalidation_techapproach/#return-period-monotonicity-and-uncertainty-consistency","text":"The final hazard validation evaluates consistency of flood depths and velocities across return periods. Flood depths and velocities at a structure are expected to increase monotonically with increasing return period, following the sequence 10-, 20-, 50-, 100-, 200-, 500-, 1,000-, and 2,000-year events. Structures are flagged when this monotonic relationship is violated, as such patterns may indicate issues with hazard surface generation, interpolation artifacts, or uncertainty handling. This validation extends to cases where uncertainty is applied. Minimum and maximum hazard values derived from uncertainty bounds are expected to preserve the same increasing relationship across return periods. For example, the minimum flood depth for the 2,000-year event, even when computed as mean minus standard deviation, should exceed the corresponding minimum for the 1,000-year event. Violations of this expectation are flagged for review to ensure internal consistency of probabilistic hazard inputs.","title":"Return Period Monotonicity and Uncertainty Consistency"},{"location":"hazardvalidation_techapproach/#outputs-and-use-of-hazard-validation-flags","text":"Each hazard validation condition produces a discrete, non-blocking flag accompanied by plain-language guidance indicating the nature of the anomaly and the recommended focus of review. Flags are advisory and are intended to support transparency, diagnostics, and informed quality assurance without interrupting loss modeling workflows. Collectively, these validations provide a structured framework for identifying potential hazard and loss inconsistencies while preserving analytical continuity.","title":"Outputs and Use of Hazard Validation Flags"},{"location":"inland_methodology/","text":"Inland Consquences Methodology \u00b6 Hazard Data Inputs \u00b6 The inland consequence methodology relies on a set of core hazard layers that describe the depth (required), uncertainty (optional), velocity (optional), and duration (optional) of flooding at each location. These inputs collectively guide the selection of the appropriate depth-damage functions and determine the damage to the structure associated cost. While the methodology is designed for FEMA\u2019s Future Flood Risk Data (FFRD) post-processed annual exceedance probably (AEP) flood depth rasters and their associated velocity, duration and uncertainty layers, it is designed to be flexible and can operate with any user-provided hazard data that meets the required formats. The sections below describe the role, requirements, and assumptions associated with each hazard input. Flood Depth \u00b6 Flood depth rasters are the primary hazard input driving the inland consequence calculations and only required hazard input. The methodology is built to ingest FEMA\u2019s post-processed AEP depth rasters for multiple return periods, but it is flexible enough to operate with any valid flood depth raster. Under normal use, the tool expects depth inputs for several AEPs, allowing annualized losses to be computed from a consistent hazard set. Users may modify the number of AEPs depending on the data available, however a minimum of three return periods is required to calculate average annualized loss. Depth values must be provided in units of feet. The tool can also run in single-event mode by ingesting a single depth raster representing a historical or design event; in this configuration, the tool produces an event-specific loss rather than an annualized estimate. At this time, the methodology does not ingest the full suite of FFRD Monte Carlo simulation rasters to compute annualized losses directly from the simulation ensemble; this capability is identified as a future enhancement. Flood Depth Uncertainty \u00b6 Flood depth uncertainty rasters provide information on the variability of the predicted flood depth for each AEP. When supplied, these uncertainty layers allow the methodology to explore loss sensitivity and characterize uncertainty more explicitly within the loss calculation process. One uncertainty raster is expected per AEP return period, and the units mirror those of the depth rasters (feet). Although optional, these layers are recommended for users who want to evaluate the robustness of loss estimates or conduct probabilistic analyses. When uncertainty rasters are not provided, the methodology proceeds deterministically using the best-estimate depth values only. Flood Velocity \u00b6 Velocity data support the classification of flood hazard peril and influence the selection of the appropriate depth-damage functions. When a velocity raster is provided, the methodology evaluates each structure\u2019s exposure to high-velocity flow conditions. Velocities exceeding 5 feet per second are treated as high-velocity flooding and may result in the application of different or more severe DDFs. Values below this threshold are classified as low-velocity conditions. If a velocity raster is not supplied, the methodology defaults to assuming low-velocity flooding for all structures. More detail on how velocity interacts with DDF selection is provided in the Hazard Peril section . Flood Duration \u00b6 Flood duration rasters are used to determine whether structures are exposed to long-duration inundation, which can significantly affect building performance and loss outcomes. Duration values must be provided in hours, with exposures greater than 72 hours classified as long-duration flooding. This classification may influence which depth-damage functions are applied. When no duration raster is provided, the methodology assumes short-duration flooding for all structures. As with velocity, duration-based peril classification is further discussed in the Hazard Peril section . File Types \u00b6 Hazard data is compatible with existing file export formats such as GeoTIFFs and TIFFs, consistent with previous consequence solutions like the Hazus Flood Assessment Structure Tool (FAST) and early FFRD pilot outputs. However, because the final FFRD datasets and file formats are still being defined, additional support has also been implemented for cloud-optimized formats, including Zarr and Xarray-based readers. Depth-Damage Function (DDF) Assignment \u00b6 The inland consequence methodology assigns depth-damage functions (DDFs) by integrating key building and hazard characteristics: general building type, occupancy type, square footage, number of stories, foundation type, and flood hazard peril type. These elements collectively determine how a structure is expected to perform under various flooding conditions and which DDF function should be applied to calculate percent damage at a given depth in structure. The methodology follows the principles and thresholds developed through the OpenHazus initiative and is designed to maintain alignment with FEMA\u2019s broader approach to flood consequence modeling. General Building Type \u00b6 The general building type describes a building\u2019s construction type and the primary materials used in its construction and is a key factor in understanding how the building responds to flood events. Flood general building types include wood (W), masonry (M), concrete (C), steel (S), and manufactured housing (MH). If the flood general building type is unknown, wood is assumed by default. Occupancy Type \u00b6 Occupancy type is a primary input used to select appropriate DDFs by grouping structures with similar use and vulnerability characteristics. The assigned occupancy type informs both the structure and contents damage relationships applied during flood loss estimation. The occupancy types used in this methodology are listed in Table 1. If the occupancy type is unknown, RES1 is assumed by default. Table 1. Occupancy Types Occupancy Type Description RES1 Single-family Dwelling RES2 Mobile Home RES3A Multi-Family Dwelling - Duplex RES3B Multi-Family Dwelling - 3-4 Units RES3C Multi-Family Dwelling - 5-9 Units RES3D Multi-Family Dwelling - 10-19 Units RES3E Multi-Family Dwelling - 20-49 Units RES3F Multi-Family Dwelling - 50+ Units RES4 Temporary Lodging RES5 Institutional Dormitory RES6 Nursing Home COM1 Retail Trade COM2 Wholesale Trade COM3 Personal and Repair Services COM4 Business / Professional / Technical Services COM5 Depository Institutions (Banks) COM6 Hospital COM7 Medical Office / Clinic COM8 Entertainment and Recreation COM9 Theaters COM10 Parking IND1 Heavy Industrial IND2 Light Industrial IND3 Food, Drugs, and Chemicals IND4 Metals and Minerals Processing IND5 High Technology IND6 Construction AGR1 Agriculture REL1 Church / Non-Profit GOV1 General Services GOV2 Emergency Response EDU1 Schools and Libraries EDU2 Colleges and Universities Square Footage \u00b6 For selected occupancy types and general building type combinations, additional refinement of DDF selection is applied based on building area. For COM1, COM2, IND1-6 and AGR1 occupancies where the general building type is steel, structures with an area less than 4,000 square feet are treated as pre-engineered construction, while structures greater than 4,000 square feet are treated as engineered construction. This classification affects the DDFs applied to both structure and contents losses. Number of Stories \u00b6 The inland consequences methodology uses the explicit number of stories attribute rather than generic low-, mid-, or high-rise categories. This approach allows the methodology to leverage depth-damage functions developed specifically for one-, two-, and three-story structures, which represent the majority of the building stock. For each combination of general building type, occupancy type, and square footage, an expected minimum and maximum number of stories is defined based on typical real-world construction practices. If an input number of stories exceeds the expected maximum for a given attribute combination, the structure is flagged as a potential anomaly and assigned the maximum allowable number of stories for that combination when selecting the most appropriate DDF. This flag may be used by analysts to identify and evaluate potential issues in the input dataset. Table 2 shows the expected number of stories for attribute combinations. Table 2. Expected Number of Stories for Attribute Combination General Building Type Occupancy Type Square Footage Expected Number of Stories Wood RES1, RES3A All 1-4 Wood RES3B-F, RES4-6 All 1-4 Wood COM1, COM9 All 1-2 Wood COM1, COM9 All 3-6 Wood COM2-8, COM10, IND1-6, REL1, AGR1, GOV1-2, EDU1-2 All 1-6 Masonry RES1, RES3A All 1-7 Masonry RES3B All 1-7 Masonry COM1, COM9 All 1-2 Masonry IND1, AGR1 All 1 Masonry RES3C-F, RES4-6 All 1-30 Masonry COM1, COM9 All 3-30 Masonry IND1, AGR1 All 2-30 Masonry COM2-8, COM10, IND2-6, REL1, GOV1-2, EDU1-2 All 1-30 Concrete RES1, RES3A All 1-40 Concrete RES3B-F, RES4-6 All 1-40 Concrete COM1-10, IND1-6, REL1, AGR1, GOV1-2, EDU1-2 All 1-40 Steel COM1-2, IND1-6, AGR1 \\<= 4,000 sf 1 Steel RES1, RES3A-F, RES4-6 All 1-108 Steel COM1-2, IND1-6, AGR1 > 4,000 sf 1-108 Steel COM3-10, REL1, GOV1-2, EDU1-2 All 1-108 Manufactured Home RES2 All 1 If the number of stories attribute is not provided, the methodology assumes a default of one story. Foundation Type \u00b6 Foundation type is a key structural attribute that influences how buildings respond to flooding and, in cases where foundation information is missing, helps determine the default flood condition applied during loss calculation. The methodology classifies foundations into four categories: Basement, Shallow, Slab, and Pile. Each foundation type is associated with an expected default foundation height when height information is not available in the structure inventory, Table 1. Table 3. Inland Foundation Types and Default Foundation Heights Foundation Type Default Foundation Height Basement 2 ft Pile 8 ft Shallow 3 ft Slab 1 ft Based on NSI 2025 pre-release materials, an adjustment was made to the default basement foundation heights from 4 ft to 2 ft for alignment. The consequence methodology is designed to natively support the NSI 2022 Public Version, NSI 2022 Private Version, and Milliman Market Basket datasets. For additional details on how foundation types are defined and derived within these inventories, refer to the Building Inventories Technical Implementation Documentation . Hazard Peril \u00b6 Hazard peril describes the specific flood conditions a structure is exposed to and is a critical determinant of how damage progresses during an event. Different flood processes\u2014such as long-duration inundation or high-velocity flow\u2014impose distinct physical stresses on buildings, and selecting the correct peril ensures that the depth-damage function accurately reflects those conditions. For inland (riverine) flooding, the methodology classifies hazard peril based on duration and velocity. Long-duration flooding is defined as inundation lasting 72 hours or more, consistent with thresholds used in USACE\u2019s GoConsequences model. When duration data are unavailable, flooding is treated as short duration. Flow velocity is then evaluated to distinguish between low- and high-velocity conditions. High-velocity flooding is defined as flow \u2265 5 ft/s; values below this threshold are considered low velocity. If velocity data are not available, the methodology defaults to low-velocity conditions. Each structure is assigned a single riverine flood peril based on the combination of duration and velocity characteristics. The riverine peril types used in this methodology are shown in Table 3. Table 4. Riverine Flood Peril Descriptions Flood Peril Description RLS Riverine, Low Velocity, Short Duration RHS Riverine, High Velocity, Short Duration RLL Riverine, Low Velocity, Long Duration RHL Riverine, High Velocity, Long Duration DDF Assignment \u00b6 Based on general building type, occupancy type, square footage, number of stories, foundation type, and hazard peril, the methodology integrates these inputs to select the appropriate depth-damage function. This is performed through a dedicated DDF assignment module that applies a sequence of lookup tables consistent with OpenHazus conventions. The assigned DDF determines the percent damage at each depth and forms the basis for structure- and content-level loss calculations. For more details on the DDF assignment look up tables please refer to the DDF Technical Implementation Documentation . This workflow is actively advancing under the OpenHazus innovation account and the Natural Hazard Risk Assessment Program, and the modular design ensures the system can incorporate future modifications, including new building classifications, updated peril logic, probabilistic DDF selection, or integration with enhanced hazard datasets. The result is a flexible, transparent, and extensible framework for assigning depth-damage functions within the inland consequence methodology. Loss Calculations \u00b6 The inland consequence methodology calculates flood losses by combining structure-level attributes, hazard inputs, and depth-damage functions (DDFs) to estimate expected damages to buildings, contents, and inventory. The process begins by determining the flood depth at each structure and proceeds through percent-damage estimation, loss calculation, and annualization across all modeled return periods. Determining Depth in Structure \u00b6 Loss calculations begin by spatially intersecting each structure with the flood depth raster to determine the depth at the structure location. Structures with 0 or negative depths at structure will not have losses calculated as these represent dry structures. The methodology then subtracts the foundation height from this value to compute the depth in structure, which represents the depth of water relative to the occupied or finished interior of the building. For some foundation negative depths in structure will result in losses, such as finished basement where you would see damage below the first-floor. Applying Depth-Damage Functions \u00b6 Each building component (structure, contents, and inventory) has its own DDF ID and corresponding depth-damage curve. After we determine the water depth inside the structure, we use each DDF ID to look up the expected percent damage for that component. Depth-damage curves report damage at fixed depth intervals (for example, every 0.5 or 1 foot). To estimate damage at the exact water depth, the methodology interpolates between the curve\u2019s points, producing a smooth, continuous estimate. The result is three separate percent-damage values\u2014one each for structure, contents, and inventory\u2014representing how much of each component is expected to be lost at that water depth. The monetary loss for each component (structure, content and inventory) is calculated by multiplying the percent damage by its corresponding valuation amount (structure valuation, content valuation and inventory valuation). This process is followed for each return period to produce estimated losses for each return period included in the hazard dataset. For single return periods events, results are provided after this loss calculation. For multiple return periods events, an average annualized loss is calculated. Average Annualized Loss (AAL) \u00b6 After losses are computed across all available return periods, the inland consequence methodology derives the Average Annualized Loss (AAL), which represents the long-term expected loss per year. The AAL is calculated using a Riemann sum numerical integration approach, consistent with the methodology employed in FEMA\u2019s Hazus Program. Table 5 illustrates this method, in which the inland consequence solution computes annual losses for eight probabilistic return periods (RPs). The annual probability of each event is calculated as 1/RP, and differential probabilities are obtained by subtracting adjacent annual occurrence probabilities based on descending order (e.g., 2,000 year \u2013 1,000 year annual probability). The average loss for each interval is then calculated by averaging the annual losses associated with the corresponding return periods, as shown in the \u201caverage losses\u201d column. The AAL is obtained by summing the products of each average loss and its associated differential probability, resulting in a single annualized estimate of expected flood-related losses. In this approach, each pair of return-period losses and their associated frequencies is treated as a point along a continuous loss-exceedance curve. As illustrated in Figure 1, by summing up the areas of rectangles or trapezoids formed between adjacent points, the Riemann sum integrates across the full range of flood frequencies to produce the annualized loss. Two options are available for the annualization of losses for the first high frequency return period where no losses occur. The first method is to average the 0 loss with the next highest loss, which is the common default method in Hazus and the second is to truncate the lowest range. The Table 5 example below illustrates the default (non-truncate) method for an industrial building in the Duwamish watershed that is impacted by 500 year and longer return period flooding and dry at 200 year and less. This is a IND5 structure with a building value of $12,156,928. In the truncate method, the 200 year contribution to AAL is reduced by $2,912 (nearly 40% of AAL). Both options are available, and the large difference can be mitigated by using a larger number of frequencies. Table 5. Average Annualized Building Loss Estimations Return Period Annualized Probability Differential Probability Scenario Losses ($) Average Loss Formula Average Losses ($) Annualized Losses ($) 2000 0.00050000 0.00050000 2,966,772 L2000 2,966,772 1,483 1000 0.00100000 0.00050000 2,549,166 (L2000 + L1000) / 2 2,757,969 1,379 500 0.00200000 0.00100000 1,941,000 (L1000 + L500) / 2 2,245,083 2,245 200 0.00500000 0.00300000 0 (L500 + L200) / 2 970,500 2,912 100 0.01000000 0.00500000 0 (L200 + L100) / 2 50 0.02000000 0.01000000 0 (L100 + L50) / 2 20 0.05000000 0.03000000 0 (L50 + L20) / 2 10 0.10000000 0.05000000 0 (L20 + L10) / 2 Total 8,018.95 Figure 1 Illustration of Estimating Area of Loss Curve Based on Input Return periods Using Riemann Sums Method A greater number and wider range of modeled return periods yield a more complete and representative loss curve. A minimum of three return periods is required to compute AAL, though including additional frequencies improves accuracy. Contractor research indicates that using approximately 22 return periods offers an effective balance, capturing the loss curve with high fidelity while minimizing computational demands. However, decisions for FFRD pertaining to the recommended number of return periods are pending. Figure 2 PTS Contractor Research on the Recommendation for Identifying 22 return periods to represent the full Annual Exceedance Probability Curve Uncertainty \u00b6 Three major sources of uncertainty are considered: Hazard Building data and attribution Depth-Damage Functions (DDFs) Initially, the tool will provide uncertainty based on hazard and placeholders for methods to incorporate uncertainty based on building data and DDFs, as well as a combined uncertainty across all sources. FFRD input provides hazard-related uncertainty; however, an ongoing OpenHazus Innovations task is intended to refine and develop recommendations for building data, DDF and combined uncertainties. FFRD uncertainty represents the standard deviation of the hazard for a given frequency across 50 realizations for each of the return periods available. The deviation is provided in feet related to the mean flood depth and feet per second relative to the mean velocity. When these uncertainty grids are available, losses will include the minimum, mean and maximum based on mean and standard deviation. Cases where large uncertainties for long return periods result in minimum losses lower than more frequent return periods at the structure level will be flagged (e.g. 1,000 year > 2,000 year). Several OpenHazus tasks are scheduled for completion in March 2026 to evaluate and provide recommendations for uncertainty-related processes, including: Uncertainties including internal inconsistencies in % loss for each stage depth based on examples from DDF\u2019s outlined in the uncertainty white paper and from DDFs with available uncertainties (e.g. IWR, NAACs, and FEMA claims data studies). Outline the process flow for evaluating the DDF uncertainty impacts on losses. Capture assumptions and carry uncertainty through to outputs, including median losses, ranges, and probabilities. Outline how other building foundation types and height attributes are incorporated into the OpenHazus uncertainty process, including processes that consider uncertainties in occupancy, square footage, number of stories, basement/finished and value. Setup a global sensitivity analysis experimental design for total losses. Consider certain known parameters like water depth, velocity, building occupancy, foundation type, FFE, and DDF uncertainty. Complete global sensitivity analysis for pilot FFRD data. Results \u00b6 Results are provided at the structure level using a Python notebook interface. The notebook supports: A final summary table of AAL building and content losses, providing mean, minimum, and maximum values when uncertainty is available. A final summary table of actuarially adjusted AAL building, content, and inventory losses that accounts for limits and deductibles and provides mean, minimum, and maximum values when uncertainty is available. A comprehensive results table that allows users to select outputs in a variety of user-defined formats (e.g., .csv , file geodatabase, parquet). This table includes all return period and event-level building, content, and inventory losses based on mean values and available uncertainties; mean and standard deviation of flood depths at the structure and in-structure based on foundation height; damage function IDs and percent damage for structure, content, and inventory along with the corresponding depth in structure; and inventory attributes such as building and content value, occupancy, foundation type and height, number of stories, building and footprint area, and general building type. Summary options that enable aggregation of total losses by occupancy, building type, and foundation type, as well as by geographic areas such as state, county, tract, census block, HUC, and jurisdiction.","title":"Inland Consquences Methodology"},{"location":"inland_methodology/#inland-consquences-methodology","text":"","title":"Inland Consquences Methodology"},{"location":"inland_methodology/#hazard-data-inputs","text":"The inland consequence methodology relies on a set of core hazard layers that describe the depth (required), uncertainty (optional), velocity (optional), and duration (optional) of flooding at each location. These inputs collectively guide the selection of the appropriate depth-damage functions and determine the damage to the structure associated cost. While the methodology is designed for FEMA\u2019s Future Flood Risk Data (FFRD) post-processed annual exceedance probably (AEP) flood depth rasters and their associated velocity, duration and uncertainty layers, it is designed to be flexible and can operate with any user-provided hazard data that meets the required formats. The sections below describe the role, requirements, and assumptions associated with each hazard input.","title":"Hazard Data Inputs"},{"location":"inland_methodology/#flood-depth","text":"Flood depth rasters are the primary hazard input driving the inland consequence calculations and only required hazard input. The methodology is built to ingest FEMA\u2019s post-processed AEP depth rasters for multiple return periods, but it is flexible enough to operate with any valid flood depth raster. Under normal use, the tool expects depth inputs for several AEPs, allowing annualized losses to be computed from a consistent hazard set. Users may modify the number of AEPs depending on the data available, however a minimum of three return periods is required to calculate average annualized loss. Depth values must be provided in units of feet. The tool can also run in single-event mode by ingesting a single depth raster representing a historical or design event; in this configuration, the tool produces an event-specific loss rather than an annualized estimate. At this time, the methodology does not ingest the full suite of FFRD Monte Carlo simulation rasters to compute annualized losses directly from the simulation ensemble; this capability is identified as a future enhancement.","title":"Flood Depth"},{"location":"inland_methodology/#flood-depth-uncertainty","text":"Flood depth uncertainty rasters provide information on the variability of the predicted flood depth for each AEP. When supplied, these uncertainty layers allow the methodology to explore loss sensitivity and characterize uncertainty more explicitly within the loss calculation process. One uncertainty raster is expected per AEP return period, and the units mirror those of the depth rasters (feet). Although optional, these layers are recommended for users who want to evaluate the robustness of loss estimates or conduct probabilistic analyses. When uncertainty rasters are not provided, the methodology proceeds deterministically using the best-estimate depth values only.","title":"Flood Depth Uncertainty"},{"location":"inland_methodology/#flood-velocity","text":"Velocity data support the classification of flood hazard peril and influence the selection of the appropriate depth-damage functions. When a velocity raster is provided, the methodology evaluates each structure\u2019s exposure to high-velocity flow conditions. Velocities exceeding 5 feet per second are treated as high-velocity flooding and may result in the application of different or more severe DDFs. Values below this threshold are classified as low-velocity conditions. If a velocity raster is not supplied, the methodology defaults to assuming low-velocity flooding for all structures. More detail on how velocity interacts with DDF selection is provided in the Hazard Peril section .","title":"Flood Velocity"},{"location":"inland_methodology/#flood-duration","text":"Flood duration rasters are used to determine whether structures are exposed to long-duration inundation, which can significantly affect building performance and loss outcomes. Duration values must be provided in hours, with exposures greater than 72 hours classified as long-duration flooding. This classification may influence which depth-damage functions are applied. When no duration raster is provided, the methodology assumes short-duration flooding for all structures. As with velocity, duration-based peril classification is further discussed in the Hazard Peril section .","title":"Flood Duration"},{"location":"inland_methodology/#file-types","text":"Hazard data is compatible with existing file export formats such as GeoTIFFs and TIFFs, consistent with previous consequence solutions like the Hazus Flood Assessment Structure Tool (FAST) and early FFRD pilot outputs. However, because the final FFRD datasets and file formats are still being defined, additional support has also been implemented for cloud-optimized formats, including Zarr and Xarray-based readers.","title":"File Types"},{"location":"inland_methodology/#depth-damage-function-ddf-assignment","text":"The inland consequence methodology assigns depth-damage functions (DDFs) by integrating key building and hazard characteristics: general building type, occupancy type, square footage, number of stories, foundation type, and flood hazard peril type. These elements collectively determine how a structure is expected to perform under various flooding conditions and which DDF function should be applied to calculate percent damage at a given depth in structure. The methodology follows the principles and thresholds developed through the OpenHazus initiative and is designed to maintain alignment with FEMA\u2019s broader approach to flood consequence modeling.","title":"Depth-Damage Function (DDF) Assignment"},{"location":"inland_methodology/#general-building-type","text":"The general building type describes a building\u2019s construction type and the primary materials used in its construction and is a key factor in understanding how the building responds to flood events. Flood general building types include wood (W), masonry (M), concrete (C), steel (S), and manufactured housing (MH). If the flood general building type is unknown, wood is assumed by default.","title":"General Building Type"},{"location":"inland_methodology/#occupancy-type","text":"Occupancy type is a primary input used to select appropriate DDFs by grouping structures with similar use and vulnerability characteristics. The assigned occupancy type informs both the structure and contents damage relationships applied during flood loss estimation. The occupancy types used in this methodology are listed in Table 1. If the occupancy type is unknown, RES1 is assumed by default. Table 1. Occupancy Types Occupancy Type Description RES1 Single-family Dwelling RES2 Mobile Home RES3A Multi-Family Dwelling - Duplex RES3B Multi-Family Dwelling - 3-4 Units RES3C Multi-Family Dwelling - 5-9 Units RES3D Multi-Family Dwelling - 10-19 Units RES3E Multi-Family Dwelling - 20-49 Units RES3F Multi-Family Dwelling - 50+ Units RES4 Temporary Lodging RES5 Institutional Dormitory RES6 Nursing Home COM1 Retail Trade COM2 Wholesale Trade COM3 Personal and Repair Services COM4 Business / Professional / Technical Services COM5 Depository Institutions (Banks) COM6 Hospital COM7 Medical Office / Clinic COM8 Entertainment and Recreation COM9 Theaters COM10 Parking IND1 Heavy Industrial IND2 Light Industrial IND3 Food, Drugs, and Chemicals IND4 Metals and Minerals Processing IND5 High Technology IND6 Construction AGR1 Agriculture REL1 Church / Non-Profit GOV1 General Services GOV2 Emergency Response EDU1 Schools and Libraries EDU2 Colleges and Universities","title":"Occupancy Type"},{"location":"inland_methodology/#square-footage","text":"For selected occupancy types and general building type combinations, additional refinement of DDF selection is applied based on building area. For COM1, COM2, IND1-6 and AGR1 occupancies where the general building type is steel, structures with an area less than 4,000 square feet are treated as pre-engineered construction, while structures greater than 4,000 square feet are treated as engineered construction. This classification affects the DDFs applied to both structure and contents losses.","title":"Square Footage"},{"location":"inland_methodology/#number-of-stories","text":"The inland consequences methodology uses the explicit number of stories attribute rather than generic low-, mid-, or high-rise categories. This approach allows the methodology to leverage depth-damage functions developed specifically for one-, two-, and three-story structures, which represent the majority of the building stock. For each combination of general building type, occupancy type, and square footage, an expected minimum and maximum number of stories is defined based on typical real-world construction practices. If an input number of stories exceeds the expected maximum for a given attribute combination, the structure is flagged as a potential anomaly and assigned the maximum allowable number of stories for that combination when selecting the most appropriate DDF. This flag may be used by analysts to identify and evaluate potential issues in the input dataset. Table 2 shows the expected number of stories for attribute combinations. Table 2. Expected Number of Stories for Attribute Combination General Building Type Occupancy Type Square Footage Expected Number of Stories Wood RES1, RES3A All 1-4 Wood RES3B-F, RES4-6 All 1-4 Wood COM1, COM9 All 1-2 Wood COM1, COM9 All 3-6 Wood COM2-8, COM10, IND1-6, REL1, AGR1, GOV1-2, EDU1-2 All 1-6 Masonry RES1, RES3A All 1-7 Masonry RES3B All 1-7 Masonry COM1, COM9 All 1-2 Masonry IND1, AGR1 All 1 Masonry RES3C-F, RES4-6 All 1-30 Masonry COM1, COM9 All 3-30 Masonry IND1, AGR1 All 2-30 Masonry COM2-8, COM10, IND2-6, REL1, GOV1-2, EDU1-2 All 1-30 Concrete RES1, RES3A All 1-40 Concrete RES3B-F, RES4-6 All 1-40 Concrete COM1-10, IND1-6, REL1, AGR1, GOV1-2, EDU1-2 All 1-40 Steel COM1-2, IND1-6, AGR1 \\<= 4,000 sf 1 Steel RES1, RES3A-F, RES4-6 All 1-108 Steel COM1-2, IND1-6, AGR1 > 4,000 sf 1-108 Steel COM3-10, REL1, GOV1-2, EDU1-2 All 1-108 Manufactured Home RES2 All 1 If the number of stories attribute is not provided, the methodology assumes a default of one story.","title":"Number of Stories"},{"location":"inland_methodology/#foundation-type","text":"Foundation type is a key structural attribute that influences how buildings respond to flooding and, in cases where foundation information is missing, helps determine the default flood condition applied during loss calculation. The methodology classifies foundations into four categories: Basement, Shallow, Slab, and Pile. Each foundation type is associated with an expected default foundation height when height information is not available in the structure inventory, Table 1. Table 3. Inland Foundation Types and Default Foundation Heights Foundation Type Default Foundation Height Basement 2 ft Pile 8 ft Shallow 3 ft Slab 1 ft Based on NSI 2025 pre-release materials, an adjustment was made to the default basement foundation heights from 4 ft to 2 ft for alignment. The consequence methodology is designed to natively support the NSI 2022 Public Version, NSI 2022 Private Version, and Milliman Market Basket datasets. For additional details on how foundation types are defined and derived within these inventories, refer to the Building Inventories Technical Implementation Documentation .","title":"Foundation Type"},{"location":"inland_methodology/#hazard-peril","text":"Hazard peril describes the specific flood conditions a structure is exposed to and is a critical determinant of how damage progresses during an event. Different flood processes\u2014such as long-duration inundation or high-velocity flow\u2014impose distinct physical stresses on buildings, and selecting the correct peril ensures that the depth-damage function accurately reflects those conditions. For inland (riverine) flooding, the methodology classifies hazard peril based on duration and velocity. Long-duration flooding is defined as inundation lasting 72 hours or more, consistent with thresholds used in USACE\u2019s GoConsequences model. When duration data are unavailable, flooding is treated as short duration. Flow velocity is then evaluated to distinguish between low- and high-velocity conditions. High-velocity flooding is defined as flow \u2265 5 ft/s; values below this threshold are considered low velocity. If velocity data are not available, the methodology defaults to low-velocity conditions. Each structure is assigned a single riverine flood peril based on the combination of duration and velocity characteristics. The riverine peril types used in this methodology are shown in Table 3. Table 4. Riverine Flood Peril Descriptions Flood Peril Description RLS Riverine, Low Velocity, Short Duration RHS Riverine, High Velocity, Short Duration RLL Riverine, Low Velocity, Long Duration RHL Riverine, High Velocity, Long Duration","title":"Hazard Peril"},{"location":"inland_methodology/#ddf-assignment","text":"Based on general building type, occupancy type, square footage, number of stories, foundation type, and hazard peril, the methodology integrates these inputs to select the appropriate depth-damage function. This is performed through a dedicated DDF assignment module that applies a sequence of lookup tables consistent with OpenHazus conventions. The assigned DDF determines the percent damage at each depth and forms the basis for structure- and content-level loss calculations. For more details on the DDF assignment look up tables please refer to the DDF Technical Implementation Documentation . This workflow is actively advancing under the OpenHazus innovation account and the Natural Hazard Risk Assessment Program, and the modular design ensures the system can incorporate future modifications, including new building classifications, updated peril logic, probabilistic DDF selection, or integration with enhanced hazard datasets. The result is a flexible, transparent, and extensible framework for assigning depth-damage functions within the inland consequence methodology.","title":"DDF Assignment"},{"location":"inland_methodology/#loss-calculations","text":"The inland consequence methodology calculates flood losses by combining structure-level attributes, hazard inputs, and depth-damage functions (DDFs) to estimate expected damages to buildings, contents, and inventory. The process begins by determining the flood depth at each structure and proceeds through percent-damage estimation, loss calculation, and annualization across all modeled return periods.","title":"Loss Calculations"},{"location":"inland_methodology/#determining-depth-in-structure","text":"Loss calculations begin by spatially intersecting each structure with the flood depth raster to determine the depth at the structure location. Structures with 0 or negative depths at structure will not have losses calculated as these represent dry structures. The methodology then subtracts the foundation height from this value to compute the depth in structure, which represents the depth of water relative to the occupied or finished interior of the building. For some foundation negative depths in structure will result in losses, such as finished basement where you would see damage below the first-floor.","title":"Determining Depth in Structure"},{"location":"inland_methodology/#applying-depth-damage-functions","text":"Each building component (structure, contents, and inventory) has its own DDF ID and corresponding depth-damage curve. After we determine the water depth inside the structure, we use each DDF ID to look up the expected percent damage for that component. Depth-damage curves report damage at fixed depth intervals (for example, every 0.5 or 1 foot). To estimate damage at the exact water depth, the methodology interpolates between the curve\u2019s points, producing a smooth, continuous estimate. The result is three separate percent-damage values\u2014one each for structure, contents, and inventory\u2014representing how much of each component is expected to be lost at that water depth. The monetary loss for each component (structure, content and inventory) is calculated by multiplying the percent damage by its corresponding valuation amount (structure valuation, content valuation and inventory valuation). This process is followed for each return period to produce estimated losses for each return period included in the hazard dataset. For single return periods events, results are provided after this loss calculation. For multiple return periods events, an average annualized loss is calculated.","title":"Applying Depth-Damage Functions"},{"location":"inland_methodology/#average-annualized-loss-aal","text":"After losses are computed across all available return periods, the inland consequence methodology derives the Average Annualized Loss (AAL), which represents the long-term expected loss per year. The AAL is calculated using a Riemann sum numerical integration approach, consistent with the methodology employed in FEMA\u2019s Hazus Program. Table 5 illustrates this method, in which the inland consequence solution computes annual losses for eight probabilistic return periods (RPs). The annual probability of each event is calculated as 1/RP, and differential probabilities are obtained by subtracting adjacent annual occurrence probabilities based on descending order (e.g., 2,000 year \u2013 1,000 year annual probability). The average loss for each interval is then calculated by averaging the annual losses associated with the corresponding return periods, as shown in the \u201caverage losses\u201d column. The AAL is obtained by summing the products of each average loss and its associated differential probability, resulting in a single annualized estimate of expected flood-related losses. In this approach, each pair of return-period losses and their associated frequencies is treated as a point along a continuous loss-exceedance curve. As illustrated in Figure 1, by summing up the areas of rectangles or trapezoids formed between adjacent points, the Riemann sum integrates across the full range of flood frequencies to produce the annualized loss. Two options are available for the annualization of losses for the first high frequency return period where no losses occur. The first method is to average the 0 loss with the next highest loss, which is the common default method in Hazus and the second is to truncate the lowest range. The Table 5 example below illustrates the default (non-truncate) method for an industrial building in the Duwamish watershed that is impacted by 500 year and longer return period flooding and dry at 200 year and less. This is a IND5 structure with a building value of $12,156,928. In the truncate method, the 200 year contribution to AAL is reduced by $2,912 (nearly 40% of AAL). Both options are available, and the large difference can be mitigated by using a larger number of frequencies. Table 5. Average Annualized Building Loss Estimations Return Period Annualized Probability Differential Probability Scenario Losses ($) Average Loss Formula Average Losses ($) Annualized Losses ($) 2000 0.00050000 0.00050000 2,966,772 L2000 2,966,772 1,483 1000 0.00100000 0.00050000 2,549,166 (L2000 + L1000) / 2 2,757,969 1,379 500 0.00200000 0.00100000 1,941,000 (L1000 + L500) / 2 2,245,083 2,245 200 0.00500000 0.00300000 0 (L500 + L200) / 2 970,500 2,912 100 0.01000000 0.00500000 0 (L200 + L100) / 2 50 0.02000000 0.01000000 0 (L100 + L50) / 2 20 0.05000000 0.03000000 0 (L50 + L20) / 2 10 0.10000000 0.05000000 0 (L20 + L10) / 2 Total 8,018.95 Figure 1 Illustration of Estimating Area of Loss Curve Based on Input Return periods Using Riemann Sums Method A greater number and wider range of modeled return periods yield a more complete and representative loss curve. A minimum of three return periods is required to compute AAL, though including additional frequencies improves accuracy. Contractor research indicates that using approximately 22 return periods offers an effective balance, capturing the loss curve with high fidelity while minimizing computational demands. However, decisions for FFRD pertaining to the recommended number of return periods are pending. Figure 2 PTS Contractor Research on the Recommendation for Identifying 22 return periods to represent the full Annual Exceedance Probability Curve","title":"Average Annualized Loss (AAL)"},{"location":"inland_methodology/#uncertainty","text":"Three major sources of uncertainty are considered: Hazard Building data and attribution Depth-Damage Functions (DDFs) Initially, the tool will provide uncertainty based on hazard and placeholders for methods to incorporate uncertainty based on building data and DDFs, as well as a combined uncertainty across all sources. FFRD input provides hazard-related uncertainty; however, an ongoing OpenHazus Innovations task is intended to refine and develop recommendations for building data, DDF and combined uncertainties. FFRD uncertainty represents the standard deviation of the hazard for a given frequency across 50 realizations for each of the return periods available. The deviation is provided in feet related to the mean flood depth and feet per second relative to the mean velocity. When these uncertainty grids are available, losses will include the minimum, mean and maximum based on mean and standard deviation. Cases where large uncertainties for long return periods result in minimum losses lower than more frequent return periods at the structure level will be flagged (e.g. 1,000 year > 2,000 year). Several OpenHazus tasks are scheduled for completion in March 2026 to evaluate and provide recommendations for uncertainty-related processes, including: Uncertainties including internal inconsistencies in % loss for each stage depth based on examples from DDF\u2019s outlined in the uncertainty white paper and from DDFs with available uncertainties (e.g. IWR, NAACs, and FEMA claims data studies). Outline the process flow for evaluating the DDF uncertainty impacts on losses. Capture assumptions and carry uncertainty through to outputs, including median losses, ranges, and probabilities. Outline how other building foundation types and height attributes are incorporated into the OpenHazus uncertainty process, including processes that consider uncertainties in occupancy, square footage, number of stories, basement/finished and value. Setup a global sensitivity analysis experimental design for total losses. Consider certain known parameters like water depth, velocity, building occupancy, foundation type, FFE, and DDF uncertainty. Complete global sensitivity analysis for pilot FFRD data.","title":"Uncertainty"},{"location":"inland_methodology/#results","text":"Results are provided at the structure level using a Python notebook interface. The notebook supports: A final summary table of AAL building and content losses, providing mean, minimum, and maximum values when uncertainty is available. A final summary table of actuarially adjusted AAL building, content, and inventory losses that accounts for limits and deductibles and provides mean, minimum, and maximum values when uncertainty is available. A comprehensive results table that allows users to select outputs in a variety of user-defined formats (e.g., .csv , file geodatabase, parquet). This table includes all return period and event-level building, content, and inventory losses based on mean values and available uncertainties; mean and standard deviation of flood depths at the structure and in-structure based on foundation height; damage function IDs and percent damage for structure, content, and inventory along with the corresponding depth in structure; and inventory attributes such as building and content value, occupancy, foundation type and height, number of stories, building and footprint area, and general building type. Summary options that enable aggregation of total losses by occupancy, building type, and foundation type, as well as by geographic areas such as state, county, tract, census block, HUC, and jurisdiction.","title":"Results"},{"location":"inventory_methodology/","text":"Inventory Methodology \u00b6 The Consequences Solution is designed to operate out of the box with two predefined national inventories: the National Structures Inventory (NSI) and the Milliman Market Basket Data . Users may also integrate their own custom structure inventories by defining a corresponding JSON schema . For additional guidance on NSI Milliman inventories, and configuring and loading custom inventories, refer to the Technical Implementation Documentation . Inventory Dataset Format \u00b6 The Consequences Solution currently accepts input inventory datasets in point geometry format, representing the location of each structure to be analyzed. Supported input formats include Comma-Separated Values (.csv) , Esri Shapefile (.shp) , File Geodatabase (.gdb) , and GeoPackage (.gpkg) . Each record should include the required attribute fields used in the loss calculations, and all spatial data should be stored in a projected coordinate system appropriate for the analysis extent. Using point-based inputs ensures compatibility with the consequence modeling workflow and enables efficient spatial joins with hazard and inventory datasets. Inventory Attributes Used in Analysis \u00b6 The following attributes are used in the Consequences Solution loss calculations. While providing all recommended fields from the input inventory dataset ensures more accurate loss estimates, missing attributes will automatically be populated with default values . However, reliance on these defaults may reduce the precision of results. Loss calculations for inland and coastal areas require different sets of input attributes. Table 1 outlines the required inventory inputs for inland loss calculations, while Table 4 details the corresponding inputs for coastal loss calculations. Table 1. Inventory Input Data Requirements for Inland Consequence Modeling Input Data Required / Optional Purpose Default Process If Data Not Provided Geometry Required Locational geometry is required for spatial analysis. None, required input. If the input type is CSV, then x/y fields are required instead of a geomtry field. Unique ID Required Used for identifying the structure throughout analysis. None, required input. Occupancy Type Optional Primary use is for the selection of depth damage functions in analysis. A secondary use is to provide default values if square footage/area attribution is unavailable. Defaults to RES1 . Building Value Required Used for the calculation of structural loss. None, required input. See Hazus Inventory Manual if guidance is required. Content Value Optional Used for the calculation of content loss. If not provided, structures will be assigned a default content value based on a percentage of the building value for each Occupancy Type following the Hazus Methodology. See Table 3 for percentages by occupancy type. Number of Stories Optional Used for the assignment of depth damage functions in analysis. Defaults to 1 story . Important for RES1 when available, as DDFs differ significantly. Cannot exceed 3 for RES1. Area / Square Footage Optional Used for assigning depth damage functions and for calculations such as debris and income-related losses. If not provided, structures will be assigned a default area based on typical square footage by Occupancy Type from the Hazus Methodology (see Table 2 ). General Building Type Optional Used for assignment of depth damage function for inland analysis. Defaults to W (Wood) . Hazus tract-level mapping schemes by occupancy type ( hzGenBldgScheme ) can be used to enhance inventories. Foundation Type Optional Used for selecting the appropriate depth damage function. Defaults to Slab . Hazus mapping schemes (also used by NSI ) are available for users to enhance inventories. Foundation Height Optional Used to determine depth of water within a structure. Defaults: Slab = 1 ft , Shallow = 3 ft , Pile = 8 ft , Basement = 2 ft . Adjustments can be considered for pre- and post-FIRM structures. Foundation Type from Parcel Data Optional Used, if available, to refine foundation type assignment. -- Basement Type from Parcel Data Optional Used, if available, to refine foundation type assignment. -- Table 2. Hazus Methodology for Default Building Square Footage by Occupancy Type Occupancy Type Square Footage AGR1 30,000 COM1 110,000 COM10 145,000 COM2 30,000 COM3 10,000 COM4 80,000 COM5 4,100 COM6 55,000 COM7 7,000 COM8 5,000 COM9 12,000 EDU1 130,000 EDU2 50,000 GOV1 11,000 GOV2 11,000 IND1 30,000 IND2 30,000 IND3 45,000 IND4 45,000 IND5 45,000 IND6 30,000 REL1 17,000 RES1 1,800 RES2 1,475 RES3A 2,200 RES3B 4,400 RES3C 8,000 RES3D 15,000 RES3E 40,000 RES3F 80,000 RES4 135,000 RES5 25,000 RES6 25,000 Table 3. Content Value as Percent of Building Value by Occupancy Type Occupancy Type Content Value (%) AGR1 100% COM1 100% COM10 50% COM2 100% COM3 100% COM4 100% COM5 100% COM6 150% COM7 150% COM8 100% COM9 100% EDU1 100% EDU2 150% GOV1 100% GOV2 150% IND1 150% IND2 150% IND3 150% IND4 150% IND5 150% IND6 100% REL1 100% RES1 50% RES2 50% RES3A 50% RES3B 50% RES3C 50% RES3D 50% RES3E 50% RES3F 50% RES4 50% RES5 50% RES6 50% Table 4. Inventory Input Data Requirements for Coastal Consequence Modeling Input Data Required / Optional Purpose Default Process Geometry Required Locational geometry is required for spatial analysis. None, required input. If the input type is CSV, then x/y fields are required instead of a geomtry field. Unique ID Required Used for identifying the structure throughout analysis. None, required input. Building Value Required Used for the calculation of structural loss. None, required input. Ground Elevation Required Used to determine depth of water in structure. None, required input. Number of Stories Optional Used for the assignment of depth damage functions in analysis. Defaults to 1 story if data not provided. Foundation Type Optional Used for the selection of the depth damage function. Defaults to Slab . Foundation Height / First Floor Height Optional Used for determining depth of water within a structure. Defaults: Basement = 4 ft , Crawlspace = (unspecified) , Pier = 5 ft , Fill = 3 ft , Slab = 1 ft , Pile/Wall = 8 ft . Adjustments may be applied for pre- and post-FIRM structures. Basement Type Optional Used for determining damage function. Defaults to No Basement . Content Insurance Deductible Optional Not used for loss calculations. None. Content Insurance Limit Optional Not used for loss calculations. None. Building Insurance Deductible Optional Not used for loss calculations. None. Building Insurance Limit Optional Not used for loss calculations. None.","title":"Inventory Methodology"},{"location":"inventory_methodology/#inventory-methodology","text":"The Consequences Solution is designed to operate out of the box with two predefined national inventories: the National Structures Inventory (NSI) and the Milliman Market Basket Data . Users may also integrate their own custom structure inventories by defining a corresponding JSON schema . For additional guidance on NSI Milliman inventories, and configuring and loading custom inventories, refer to the Technical Implementation Documentation .","title":"Inventory Methodology"},{"location":"inventory_methodology/#inventory-dataset-format","text":"The Consequences Solution currently accepts input inventory datasets in point geometry format, representing the location of each structure to be analyzed. Supported input formats include Comma-Separated Values (.csv) , Esri Shapefile (.shp) , File Geodatabase (.gdb) , and GeoPackage (.gpkg) . Each record should include the required attribute fields used in the loss calculations, and all spatial data should be stored in a projected coordinate system appropriate for the analysis extent. Using point-based inputs ensures compatibility with the consequence modeling workflow and enables efficient spatial joins with hazard and inventory datasets.","title":"Inventory Dataset Format"},{"location":"inventory_methodology/#inventory-attributes-used-in-analysis","text":"The following attributes are used in the Consequences Solution loss calculations. While providing all recommended fields from the input inventory dataset ensures more accurate loss estimates, missing attributes will automatically be populated with default values . However, reliance on these defaults may reduce the precision of results. Loss calculations for inland and coastal areas require different sets of input attributes. Table 1 outlines the required inventory inputs for inland loss calculations, while Table 4 details the corresponding inputs for coastal loss calculations. Table 1. Inventory Input Data Requirements for Inland Consequence Modeling Input Data Required / Optional Purpose Default Process If Data Not Provided Geometry Required Locational geometry is required for spatial analysis. None, required input. If the input type is CSV, then x/y fields are required instead of a geomtry field. Unique ID Required Used for identifying the structure throughout analysis. None, required input. Occupancy Type Optional Primary use is for the selection of depth damage functions in analysis. A secondary use is to provide default values if square footage/area attribution is unavailable. Defaults to RES1 . Building Value Required Used for the calculation of structural loss. None, required input. See Hazus Inventory Manual if guidance is required. Content Value Optional Used for the calculation of content loss. If not provided, structures will be assigned a default content value based on a percentage of the building value for each Occupancy Type following the Hazus Methodology. See Table 3 for percentages by occupancy type. Number of Stories Optional Used for the assignment of depth damage functions in analysis. Defaults to 1 story . Important for RES1 when available, as DDFs differ significantly. Cannot exceed 3 for RES1. Area / Square Footage Optional Used for assigning depth damage functions and for calculations such as debris and income-related losses. If not provided, structures will be assigned a default area based on typical square footage by Occupancy Type from the Hazus Methodology (see Table 2 ). General Building Type Optional Used for assignment of depth damage function for inland analysis. Defaults to W (Wood) . Hazus tract-level mapping schemes by occupancy type ( hzGenBldgScheme ) can be used to enhance inventories. Foundation Type Optional Used for selecting the appropriate depth damage function. Defaults to Slab . Hazus mapping schemes (also used by NSI ) are available for users to enhance inventories. Foundation Height Optional Used to determine depth of water within a structure. Defaults: Slab = 1 ft , Shallow = 3 ft , Pile = 8 ft , Basement = 2 ft . Adjustments can be considered for pre- and post-FIRM structures. Foundation Type from Parcel Data Optional Used, if available, to refine foundation type assignment. -- Basement Type from Parcel Data Optional Used, if available, to refine foundation type assignment. -- Table 2. Hazus Methodology for Default Building Square Footage by Occupancy Type Occupancy Type Square Footage AGR1 30,000 COM1 110,000 COM10 145,000 COM2 30,000 COM3 10,000 COM4 80,000 COM5 4,100 COM6 55,000 COM7 7,000 COM8 5,000 COM9 12,000 EDU1 130,000 EDU2 50,000 GOV1 11,000 GOV2 11,000 IND1 30,000 IND2 30,000 IND3 45,000 IND4 45,000 IND5 45,000 IND6 30,000 REL1 17,000 RES1 1,800 RES2 1,475 RES3A 2,200 RES3B 4,400 RES3C 8,000 RES3D 15,000 RES3E 40,000 RES3F 80,000 RES4 135,000 RES5 25,000 RES6 25,000 Table 3. Content Value as Percent of Building Value by Occupancy Type Occupancy Type Content Value (%) AGR1 100% COM1 100% COM10 50% COM2 100% COM3 100% COM4 100% COM5 100% COM6 150% COM7 150% COM8 100% COM9 100% EDU1 100% EDU2 150% GOV1 100% GOV2 150% IND1 150% IND2 150% IND3 150% IND4 150% IND5 150% IND6 100% REL1 100% RES1 50% RES2 50% RES3A 50% RES3B 50% RES3C 50% RES3D 50% RES3E 50% RES3F 50% RES4 50% RES5 50% RES6 50% Table 4. Inventory Input Data Requirements for Coastal Consequence Modeling Input Data Required / Optional Purpose Default Process Geometry Required Locational geometry is required for spatial analysis. None, required input. If the input type is CSV, then x/y fields are required instead of a geomtry field. Unique ID Required Used for identifying the structure throughout analysis. None, required input. Building Value Required Used for the calculation of structural loss. None, required input. Ground Elevation Required Used to determine depth of water in structure. None, required input. Number of Stories Optional Used for the assignment of depth damage functions in analysis. Defaults to 1 story if data not provided. Foundation Type Optional Used for the selection of the depth damage function. Defaults to Slab . Foundation Height / First Floor Height Optional Used for determining depth of water within a structure. Defaults: Basement = 4 ft , Crawlspace = (unspecified) , Pier = 5 ft , Fill = 3 ft , Slab = 1 ft , Pile/Wall = 8 ft . Adjustments may be applied for pre- and post-FIRM structures. Basement Type Optional Used for determining damage function. Defaults to No Basement . Content Insurance Deductible Optional Not used for loss calculations. None. Content Insurance Limit Optional Not used for loss calculations. None. Building Insurance Deductible Optional Not used for loss calculations. None. Building Insurance Limit Optional Not used for loss calculations. None.","title":"Inventory Attributes Used in Analysis"},{"location":"tasks/","text":"Project Tasks \u00b6 Establish Project Output Requirements and Use Cases Evaluation of Existing Tools Understanding the Computational Approach Standardize Coastal and Inland Consequences Methodologies Integration of Inland Damage Functions Agile Prototyping Develop Production-Level Inland Consequence Solution Final Report","title":"Project Tasks"},{"location":"tasks/#project-tasks","text":"Establish Project Output Requirements and Use Cases Evaluation of Existing Tools Understanding the Computational Approach Standardize Coastal and Inland Consequences Methodologies Integration of Inland Damage Functions Agile Prototyping Develop Production-Level Inland Consequence Solution Final Report","title":"Project Tasks"},{"location":"user-requirements/","text":"User Requirements \u00b6","title":"User Requirements"},{"location":"user-requirements/#user-requirements","text":"","title":"User Requirements"}]}